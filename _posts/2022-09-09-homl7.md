---
layout: single
title: "앙상블 학습과 랜덤 포레스트"
categories: Hands-On-ML
tag: [ML]
toc: true
---







# 들어가며

- 대중의 지혜
- 무작위로 선택된 수천 명의 사람에게 복잡한 질문을 하고 대답을 모으는 것이 전문가의 답보다 낫다.
- 이와 유사한 것이 **앙상블 학습**
  - 일련의 예측기 (ex. 분류나 회귀모델)로부터 예측을 수집
  - 다양한 분류기를 만드는 방법
    1. 각기 다른 훈련 알고리즘을 사용
    2. 같은 알고리즘을 사용하고 훈련 세트의 서브셋을 무작위로 구성해 분류기를 각기 다르게 학습시키는 것
  - **앙상블** : 일련의 예측기
  - **앙상블 방법** : 앙상블 학습 알고리즘
    - **랜덤 포레스트**
      1. 훈련세트로부터 무작위로 각기 다른 서브셋을 만든다
      2. 이 서브셋을 가지고 일련의 결정트리 분류기를 훈련시킨다
      3. 모든 개별 트리의 예측을 구한다
      4. 가장 많은 선택을 받은 클래스를 예측으로 삼는다
    - **배깅, 부스팅, 스태킹**









# 투표 기반 분류기

- **직접 투표** 분류기
  - 정확도가 80%인 분류기 여러 개를 훈련시켰다고 가정
    - ex) 로지스틱 회귀 분류기, SVM 분류기, 랜덤 포레스트 분류기, K-최근접 이웃 분류기 등
  - 각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측하는 것
  - ![image](https://user-images.githubusercontent.com/97875918/189267133-deb049e9-9896-40e2-9849-bdfce3704fda.png)
  - 각 분류기가 **약한 학습기**일지라도 충분히 많고 다양하면 앙상블은 **강한 학습기**가 된다.
  - **큰 수의 법칙**
    - ![image](https://user-images.githubusercontent.com/97875918/189268271-2342cad2-a485-4a42-ae78-ebe162e9eeeb.png)
    - 앞 51% 뒤 49% 나오는 균형이 어긋난 동전을 던진다고 가정
    - 이 동전을 1000번 던지면 510번은 앞면, 490번은 뒷면 -> 앞면이 다수가 될 확률은 75%
    - 더 많이 던질수록 앞면이 절반 이상 나올 확률은 증가함
  - 이와 유사한 51%의 정확도를 가진 1000개의 분류기로 앙상블 모델을 구축한다고 *가정*
    - 가장 많은 클래스를 예측으로 삼는다면 75%의 정확도를 기대함
  - **유의사항**
    - 모든 분류기가 완벽히 독립적
      - 앙상블 방법은 예측기가 가능한 한 독립적일 때 최고의 성능
        - 다양한 분류기로 예측하기
          - 다른 알고리즘으로 학습
        - 매우 다른 종류의 오차를 만들 가능성이 높아짐 -> 앙상블 모델의 정확도를 향상시킴
    - 오차에 상관관계가 없어야 됨
  - 즉 위의 *가정*은 **같은 데이터로 훈련**시키기 때문에 **위반**됨
    - 분류기들이 같은 종류의 오차를 만들기 쉽다 -> 잘못된 클래스가 다수
      - 앙상블의 정확도가 낮아짐





- **간접 투표**
  - 방법
    - 모든 분류기가 클래스의 확률을 예측한다. (predict_proba() 메서드 이용)
    - 개별 분류기의 예측을 평균낸다.
    - 확률이 가장 높은 클래스를 예측 한다.
  - 확률이 높은 투표에 비중을 더 두기 때문에 직접 투표 방식보다 성능이 높음
    - 코드 구현 시 `voting="hard"`를 `voting="soft"`로 바꾸기
  - 유의사항
    - SVC는 기본값에서 클래스 확률을 제공하지 않기에 `probability=True`로 지정하기









# 배깅과 페이스팅

- **배깅** (bagging)
  - 훈련 세트에서 중복을 허용해 샘플링하는 방식
  - bootstrap aggregationg
    - **bootstrapping** : 중복을 허용한 리샘플링 기법
- **페이스팅** (pasting)
  - 훈련 세트에서 중복을 허용하지 않고 샘플링 하는 방식
- 두가지 방법은 같은 훈련 샘플을 여러 개의 예측기에 걸쳐 사용할 수 있다.
  - but, 배깅만이 한 예측기를 위해 같은 훈련 샘플을 여러번 샘플링할 수 있음
    - 페이스팅은 중복을 허용하지 않아 여러번 샘플링할 수는 있으나 훈련데이터가 부족할 수 있음

<img src="https://user-images.githubusercontent.com/97875918/189271591-8c721606-1e25-4878-a2d9-18626c53ff24.png" alt="image" style="zoom:50%;" />

- 모든예측기가 훈련을 마치면 앙상블은 모든 예측기의 예측을 모아 새로운 샘플에 대한 예측을 만든다.
  - 수집함수
    - 분류일 시 : **통계적 최빈값**
      - ex) 직접 투표 분류기처럼 가장 많은 예측결과
    - 회귀일 시 : 평균을 계산
- 앙상블의 결과는 원본 데이터 셋으로 하나의 예측기를 훈련시킬 때와 비교해 편향은 비슷하지만 분산은 줄어든다.
- 예측기는 모두 동시에 다른 CPU코어, 서버에서 병렬로 학습시킬 수 있다.
  - 예측도 병렬로 수행 가능
  - 이러한 확장성으로 인해 배깅과 페이스팅의 인기가 높다.

## 사이킷런의 배깅과 페이스팅

- 사이킷런의 BaggingClassifier, BaggingRegressor

  - 배깅과 페이스팅을 위한 간편한 API로 구성

- ```python
  from sklearn.ensemble import BaggingClassifier
  from sklearn.tree import DecisionTreeClassifier
  
  bag_clf = BaggingClassifier(	# 기반이 되는 분류기가 클래스 확률 추정 가능하면 자동으로 간접투표방식
      DecisionTreeClassifier(), # 결정트리 분류기
      n_estimators=500,	# 500개의 앙상블
      max_samples=100,	# 실수 0.0~1.0사이로 지정하면 훈련세트크기*max_samples를 곱한 값
      bootstrap=True,		# 페이스팅의 경우 False로 지정
      n_jobs = -1,		# 훈련과 예측에 사용할 CPU코어 수 (-1의 경우 모든 코어 사용, 디폴트는 1)
      random_state=42)
  bag_clf.fit(X_train, y_train)
  y_pred = bag_clf.predict(X_test)
  ```

- ![image](https://user-images.githubusercontent.com/97875918/189273248-c39c6d3f-0e64-4508-8f32-9c958b58e0ad.png)

  - 왼쪽 : 단일 결정 트리 결정 경계
  - 오른쪽 : 500개의 트리 사용한 배깅 앙상블 결정 경계
  - 앙상블의 예측이 일반화가 더 잘됨
    - 앙상블은 비슷한 편향에서 더 작은 분산을 만든다.
    - 즉 훈련 세트의 오차 수가 거의 비슷하지만 결정 경계는 덜 불규칙하다.

- 정리

  - 배깅이 페이스팅보다 편향이 조금 더 높음
    - 부트스트래핑이 서브셋의 다양성을 증가시키기 때문
  - 배깅이  페이스팅보다 앙상블의 분산을 감소시킴
    - 다양성을 추가 해 예측기들의 상관관계를 줄이기 때문
  - 배깅이 더 나은 모델을 만들기에 일반적으로 선호됨
  - but, 시간+CPU 파워에 여유가 있다면 교차검증으로 모두 평가해 더 나은 쪽을 선택하자





## oob 평가

- 배깅 사용 시 어떤 샘플은 전혀 선택되지 않을 수 있다.

- BaggingClassifier는 기본값으로 중복을 허용해 훈련세트의 크기만큼인 m개 샘플을 선택한다.

  - 평균적으로 각 예측기에 훈련샘플의 63%만 샘플링된다. (e^-1과 유사)

- **oob** (out-of-bag)

  - 선택되지 않은 37%의 샘플
  - 예측기마다 남겨진 샘플은 모두 다르다.

- oob 평가

  - 예측기가 훈련되는 동안 oob 샘플을 사용하지 않으므로 별도의 검증 세트를 사용하지 않고 oob 샘플을 사용해 평가함

  - 앙상블의 평가는 각 예측기의 oob 평가를 평균하여 얻음

  - ```python
    bag_clf = BaggingClassifier(
        DecisionTreeClassifier(), n_estimators=500,
        bootstrap=True, oob_score=True, # oob_score를 True로 하면 자동으로 oob평가를 수행함
        random_state=40)
    bag_clf.fit(X_train, y_train)
    bag_clf.oob_score_ # oob평가점수 결과가 저장된 변수
    ```













# 랜덤 패치와 랜덤 서브스페이스

- BaggingClassifier는 특성 샘플링도 지원함
  - 매개변수 max_features, bootstrap_features 로 조절
    - max_samples, bootstrap과 작동 방식은 동일
    - but, 샘플이 아니라 특성에 대한 샘플링임
    - 선택한 입력 특성의 일부분으로 훈련됨
  - 매우 고차원의 데이터셋을 다룰 때 유용
  - 더 다양한 예측기를 만들며 편향을 늘리는 대신 분산을 낮춤
  - **랜덤 패치 방식** (random patches method)
    - 훈련 특성과 샘플을 모두 샘플링하는 것
  - **랜덤 서브스페이스 방식** (random subspaces method)
    - 훈련 샘플을 모두 사용
      - 매개변수 `bootstrap=False, max_samples=1.0`
    - 특성은 샘플링 함
      - 매개변수 `bootstrap_features=True 그리고/또는 max_features는 1.0보다 작게 설정`















# 랜덤 포레스트

- 배깅 방법(또는 페이스팅)을 적용한 결정 트리의 앙상블
  - 일반적으로 max_samples를 훈련 세트의 크기로 지정함
- RandomForestClassifier
  - BaggingClassifier에 DecisionTreeClassifier를 넣어 만드는 것과 동일
  - 결정 트리에 최적화되어 있는 클래스
  - 회귀문제에는 RandomForestRegressor
  - Decision Tree Classifier의 매개변수(트리 성장의 조절) BaggingClassifier 매개변수(앙상블 자체를 제어) 모두 포함
  - 트리 노드 분할 시 무작위성으로 인해 트리의 다양성을 만들어 편향을 손해보고 분산을 낮추어 좋은 모델 생성





## 엑스트라 트리

- **익스트림 랜덤 트리** (extremly randomized trees) 앙상블
  - 최적의 임곗값을 찾는 대신 후보 특성을 사용해 무작위로 분할 후 그 중 최상의 분할을 선택
    - 트리를 더욱 무작위하게 만들기 위해 
    - 랜덤포레스트보다 엑스트라 트리가 더 빠름
      - 트리 알고리즘에서 특성마다 가장 최적의 임곗값을 찾는 것이 가장 시간 소요가 많은 작업이기 때문에
  - 극단적으로 무작위한 트리의 랜덤 포레스트
  - 줄여서 **엑스트라 트리** (extra-trees)
  - 편향 증가 분산 감소
  - 사이킷런의 ExtraTreesClassifier 사용
    - 사용법은 RandomForestClassifier와 같음
    - 회귀는 ExtraTreesRegressor
  - 비교
    - RandomForestClassifier가 ExtraTreesClassifier 보다 더 나을지 나쁠지는 판단하기 어려움
    - 일반적으로 둘 다 시도 후 교차검증으로 비교하기
    - 그리드 탐색으로 하이퍼파라미터 튜닝









## 특성 중요도

- 랜덤 포레스트의 또다른 장점은 상대적 중요도를 측정하기 쉽다는 것
  - 사이킷런은 어떤 특성을 사용한 노드가 평균적으로 불순도를 얼마나 감소시키는지 확인해 특성의 중요도를 측정
  - 결정 트리의 특성 중요도
    - 노드에 사용된 특성마다
    - (현재 노드의 샘플 비율 * 불순도) - (왼쪽 자식 노드의 샘플비율 * 불순도) - (오른쪽 자식 노드의 샘플 비율 * 불순도)를 구하고
      - 샘플 비율 : 트리 전체 샘플수에 대한 비율
    - 특성 중요도의 합이 1이 되도록 특성마다 전체 합으로 나눠 정규화
  - 랜덤 포레스트의 특성 중요도
    - 각 결정 트리의 특성 중요도를 모두 계싼하여 더한 후 트리 수로 나눈 것

















# 부스팅

- 약한 학습기를 여러개 연결하여 강한 학습기를 만드는 앙상블 방법
  - 앞의 모델을 보완해나가면서 일련의 예측기를 학습시키는 것
- 원래는 **가설 부스팅** (hypothesis boosting) 이라 부름
- 인기있는 방법
  - **에이다부스트** (AdaBoost, adaptive boosting의 줄임말)와 **그레이디언트 부스팅** (gradient boosting)







## 에이다부스트

- 이전 예측기를 보완하는 새로운 예측기를 만드는 방법

  - 이전 모델이 과소적합했던 훈련 샘플의 가중치를 더 높이는 것

- ![image](https://user-images.githubusercontent.com/97875918/189290226-12cd487b-ab0f-4b3f-9ae9-ff2baba113ad.png)

  1. 알고리즘이 기반이 되는 첫번째 분류기를 훈련세트에서 훈련시키고 예측을 만든다.
  2. 알고리즘이 잘못 분류된 훈련 샘플의 가중치를 상대적으로 높인다.
     - SVC 모델에서 fit 메서드 사용 시 sample_weight 매개변수를 사용해 가중치 조절
  3. 두번째 분류기는 업데이트된 가중치를 사용해 훈련 세트에서 훈련하고 다시 예측을 만든다.
  4. 다시 가중치를 업데이트 한다.
  5. 반복

- 연속된 학습기법이 경사 하강법과 비슷하다.

  - 경사 하강법은 비용 함수를 최소화하기 위해 한 예측기의 모델 파라미터를 조정해감
  - 에이다부스트는 점차 좋아지도록 앙상블에 예측기를 추가함

- 단점

  - 각 예측기는 이전 예측기가 훈련되고 평가된 후에 학습될 수 있기에 병렬화를 할 수 없다
  - 배깅이나 페이스팅만큼 확장성이 높지 않음

- 에이다부스트의 다중 클래스 버전

  - SAMME
    - 클래스가 2개뿐일 때는 에이다부스트와 동일
    - 예측기가 클래스의 확률을 추정할 수 있다면(predict_proba() 존재)
      - SAMME.R 사용 (SAMME의 변종)
      - 예측값 대신 클래스 확률에 기반하며 일반적으로 성능이 더 좋음

- AdaBoostClassifier의 기본 추정기

  - ```python
    from sklearn.ensemble import AdaBoostClassifier
    
    ada_clf = AdaBoostClassifier(
        DecisionTreeClassifier(max_depth=1), # 깊이가 1임
        n_estimators=200, # 200개의 아주 얕은 결정트리를 기반
        algorithm="SAMME.R", learning_rate=0.5, random_state=42)
    ada_clf.fit(X_train, y_train)
    ```







## 그레이디언트 부스팅

- 앙상블에 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가함

  - but 에이다부스트처럼 반복마다 샘플의 가중치를 수정하는 대신 이전 예측기가 만든 **잔여오차**에 새로운 예측기를 학습시킴

- **그레이디언트 트리 부스팅**(gradient tree boosting) 또는 그레이디언트 부스티드 회귀트리(gradient boosted regression tree (GBRT))

  - 결정 트리를 기반 예측기로 사용하는 간단한 회귀 문제

  - ```python
    from sklearn.tree import DecisionTreeRegressor
    
    # 먼저 DTR를 훈련세트에 학습 시킴
    tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)
    tree_reg1.fit(X, y)
    
    # 첫번째 예측기에서 생긴 잔여 오차에 두번째 DTR를 훈련시킴
    y2 = y - tree_reg1.predict(X) # 잔여오차
    tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)
    tree_reg2.fit(X, y2)
    
    # 두번째 예측기가 만든 잔여오차에 세번째 DTR 훈련
    y3 = y2 - tree_reg2.predict(X)
    tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)
    tree_reg3.fit(X, y3) # 세개의 트리를 포함하는 앙상블 모델이 생김
    
    # 새로운 샘플에 대한 예측을 만들기 위해 모든 트리의 예측을 더함
    X_new = np.array([[0.8]])
    y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))
    ```

  - ![image](https://user-images.githubusercontent.com/97875918/189298817-40f891e8-8c5a-44b5-8747-8f6ebcdfd2c8.png)

    - 왼쪽 열 : 세 트리의 예측
    - 오른쪽 열 : 앙상블의 예측
    - 첫번째 행 : 앙상블에 트리가 1개 있어서 첫번째 트리의 예측과 완전히 같음
    - 트리가 앙상블에 추가될수록 앙상블의 예측이 점차 좋아짐

  - 사이킷런의 GradientBoostingRegressor

    - GBRT 앙상블을 간단하게 훈련시킬 수 있음

    - 앙상블의 훈련을 제외하는 매개변수와 결정 트리의 성장을 제어하는 매개변수 가지고 있음

    - ```python
      from sklearn.ensemble import GradientBoostingRegressor
      
      gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)
      gbrt.fit(X, y)
      ```

    - learning_rate 매개변수

      - 각 트리의 기여 정도를 조절
      - 낮게 설정 시(ex. 0.1) 앙상블을 훈련 세트에 학습시키기 위해 많은 트리가 필요
        - 예측의 성능은 좋아짐
        - **축소** (shrinkage) 라는 규제방식
      - ![image](https://user-images.githubusercontent.com/97875918/189301067-00dc8207-2b7e-4fad-959a-ad1af59b682d.png)
        - 왼쪽 : 훈련세트를 학습하기에 트리가 충분하지 않음
        - 오른쪽 : 트리가 너무 많아 훈련세트에 과대적합됨
    
  - 최적의 트리 수 찾기
  
    - 조기 종료 기법
      - 최적의 트리수를 찾기 위해 각 훈련 단계에서 검증 오차를 측정하는 방법
        - staged_predict() 메서드를 사용해 훈련의 각 단계에서 앙상블에 의해 만들어진 예측기를 순회하는 반복자를 반환
      - 연속해서 n번의 반복동안 검증오차가 향상되지 않으면 훈련을 멈추는 방법
  
  - **XGBoost**
  
    - 최적화된 그레이디언트 부스팅을 구현한 파이썬 라이브러리
    - eXtreme Gradient Boosting의 약자
    - 매우 빠른 속도, 확장성, 이식성
    - 자동조기종료의 기능 등 제공











# 스태킹

- stacked generalization의 줄임말인 stacking
- 앙상블에 속한 모든 에측기의 예측을 취합하는 간단한 함수(ex. 직접투표)를 사용하는 대신 취합하는 모델을 훈련시킬 수 없을까? 라는 아이디어에서 출발함



<img src="https://user-images.githubusercontent.com/97875918/189304946-a32a7940-5ae2-4cee-aa56-447bbae1fee4.png" alt="image" style="zoom:40%;" />

- 새로운 샘플에 회귀작업을 수행하는 앙상블
- 세 예측기는 각각 다른값을 예측함
- **블렌더** (blender) 또는 **메타 학습기** (meta learner)
  - 마지막 예측기
  - 예측들을 입력으로 받아 최종 예측을 만든다.







- 블렌더를 학습시키는 일반적인 방법
  - 홀드 아웃 세트 사용
  - <img src="https://user-images.githubusercontent.com/97875918/189305131-54bbb751-bc05-47b9-9a64-f64676bc2edf.png" alt="image" style="zoom:40%;" />
    - 첫번째 레이어 훈련하기
      - 훈련세트를 두개의 서브셋으로 나눔
      - 첫번째 서브셋은 첫번째 레이어의 예측을 훈련시키기 위해 사용
    - <img src="https://user-images.githubusercontent.com/97875918/189305345-8f62c216-dbca-45bb-94cc-edf7b3939a4b.png" alt="image" style="zoom:40%;" />
      - 블렌더 훈련
        1. 첫번째 레이어의 예측기를 사용해 두번째 (홀드아웃) 세트에 대한 예측을 만든다.
        2. 예측기들이 훈련하는 동안 이 샘플들을 전혀 보지 못했기에 이때 만들어진 예측은 완전히 새로운 것
        3. 타깃값은 그대로 쓰고 홀드 아웃 세트의 각 샘플에 대한 예측값을 입력 특성으로 사용하는 새로운 훈련세트(3차원)를 만든다. 
        4. 블렌더는 새 훈련 세트로 훈련
           - 첫 번째 레이어의 예측을 가지고 타깃값을 예측하도록 학습됨
    - <img src="https://user-images.githubusercontent.com/97875918/189305600-b8f117fc-afb5-498e-8c12-ad58d3bdd3ea.png" alt="image" style="zoom:40%;" />
      - 멀티 레이어 스태킹 앙상블의 예측
        - 블렌더를 여러 개 훈련시키는 것
          - ex) 하나는 선형회귀, 다른 하나는 랜덤 포레스트 회귀
          - 블렌더만의 레이어가 만들어짐
        - 훈련 세트를 세개의 서브셋으로 나눔
          - 첫번째 세트는 첫번째 레이어를 훈련시키는 데 사용
          - 두번째 세트는 (첫번째 레이어의 예측기로) 두번째 레이어를 훈련시키기 위한 훈련 세트를 만드는 데 사용
          - 세번째 세트는 (두번째 레이어의 예측기로) 세번째 레이어를 훈련시키기 위한 훈련 세트를 만드는 데 사용
        - 작업이 끝나면 각 레이어를 차례대로 실행해 새로운 샘플에 대한 예측을 만들 수 있다.





























