---
layout: single
title: "[n114] Data Wrangling"
categories: review
tag: [코드스테이츠, python]
toc: true
---









# 개념정리



## Tidy Data

- 지저분한 데이터의 일반적인 모습
  1. 열 이름(Column header)이 변수 이름이 아니고 값인 경우
  2. 같은 표에 다양한 관측 단위(observational units)가 있는 경우
  3. 하나의 열(column)에 여러 값이 들어 있는 경우
  4. 변수가 행과 열에 모두 포함되어 있는 경우
  5. 하나의 관측 단위(observational units)가 여러 파일로 나누어져 있는 경우
- <img src="https://user-images.githubusercontent.com/97875918/183450456-09ebc82d-cb4a-41b6-88be-73c94c6511cc.png" alt="tidy" style="zoom:67%;" />

### pivot_table

- `groupby` 명령처럼 그룹분석을 하지만 최종적으로는 `pivot` 명령처럼 피봇테이블을 만든다.
- `pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, margins_name='All')`
  - `data`: 분석할 데이터프레임 (메서드일 때는 필요하지 않음)
  - `values`: 분석할 데이터프레임에서 분석할 열
  - `index`: 행 인덱스로 들어갈 키 열 또는 키 열의 리스트
  - `columns`: 열 인덱스로 들어갈 키 열 또는 키 열의 리스트
  - `aggfunc`: 분석 메서드
  - `fill_value`: NaN 대체 값
  - `margins`: 모든 데이터를 분석한 결과를 오른쪽과 아래에 붙일지 여부
  - `margins_name`: 마진 열(행)의 이름



### melt

- `pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)`

  - `id_vars` : 기준이 될 열 입니다.
  - `value_vars` : 기준열에 대한 하위 카테고리를 나열할 열을 선택합니다.
  - `var_name` : 카테고리들이 나열된 열의 이름을 설정합니다.
  - `value_name` : 카테고리들의 값이 나열될 열의 이름을 설정합니다.
  - `col_leve` : multi index의 경우 `melt`를 수행할 레벨을 설정합니다.
  - `ignore_index` : 인덱스를 1,2,3, ... , n으로 설정할지 여부입니다. 기본적으로 `True`로 1,2,3, ... , n으로 설정됩니다.

- ```python
  # Country를 기준으로하여 Machine과 Price의 값을 하위 카데고리로 melt를 수행
  df.melt(id_vars='Country',value_vars=['Machine','Price'])
  
  # val_name, value_name 을 지정함으로써 열 이름의 기본값인 variable과 value를 원하는 값으로 변경
  df.melt(id_vars='Country',value_vars=['Machine','Price'],var_name='Category',value_name='val')
  ```

  





## 데이터 프레임 합치기(concat, merge, join)

- 열기준 컬럼명으로 합치기 : merge
- 열기준 Index명으로 합치기 : merge, concat
- 행기준으로 합치기 : concat, append



### 합치는 방법

![j1](https://user-images.githubusercontent.com/97875918/183449438-bc03e279-2d82-427a-97d7-d8cd9cc56b53.png)

- **Inner** : 두 DataFrame의 기준 컬럼에서 둘 다 존재하는 데이터만 Join
  - ![j2](https://user-images.githubusercontent.com/97875918/183449447-d5c442c7-a369-4e15-955a-3c92ee2bf6de.png)
- **Left Outer join** : 왼쪽 DataFrame으로 합치기
  - ![j3](https://user-images.githubusercontent.com/97875918/183449449-4785cfb9-1ba9-4a06-98a6-4d74e4b7335e.png)
- **Right Outer Join** : 오른쪽 DataFrame으로 합치기
  - ![j4](https://user-images.githubusercontent.com/97875918/183449453-18e7d438-7a39-4147-89b2-1232525849ae.png)
- **Outer Join** : 두 DataFrame의 모든 Data를 합치기
  - ![j5](https://user-images.githubusercontent.com/97875918/183449454-f8a16ce8-2405-4424-9a21-b3e8a86fcba3.png)



### concat

- 데이터 프레임을 물리적으로 이어 붙여주는 함수

- `pd.concat([left,right], axis, join,...)`

  - **[left,right]** : left DataFrame과 right DataFrame으로 이루어진 List
  - **axis = 0** : 행기준으로 합치기, 1: 열기준으로 Index명으로 합치기
  - ![concat](https://user-images.githubusercontent.com/97875918/183448560-691d9094-06cf-4bcf-b4b0-14a90ff3bf2c.png)

- ```python
  pd.concat([df1, df2]) #defalut 값으로 axis = 0이 적용되어 행방향으로 데이터프레임을 이어붙임
  pd.concat([df1,df2], ignore_index=True) # 인덱스를 재배열
  pd.concat([df1,df2],axis=1, join='inner') # default는 outer, 열방향으로 합치기
  ```

  

### merge

- 두 데이터 프레임을 각 데이터에 존재하는 고유값(key) 기준으로 병합할 때 사용

- `pd.merge(df_left, df_right, how='inner', on=None)` 디폴트

- `pd.merge(left, right, how, on, left_on, right_on, left_index, right_index)`

  - **left** : Merge 할 왼쪽 DataFrame
  - **right** : Merge 할 오른쪽 DataFrame
  - **how** : inner, left, right, outer
  - **on** : 두 DataFrame을 Join할 기준 컬럼명(컬럼명이 동일할 경우)
  - **left_on** : Join할 기준 컬럼의 왼쪽 DataFrame의 컬럼명
  - **right_on** : Join할 기준 컬럼의 오른쪽 DataFrame의 컬럼명
  - **left_index** : 왼쪽 DataFrame index로 Join할 경우 True
  - **right_index** : 오른쪽 DataFrame index로 Join할 경우 True

- ```python
  #공통 열이름 기준으로 교집합
  pd.merge(df1,df2)
  
  # id 기준으로 합치되 어느 한쪽에라도 없는 데이터가 있는 경우 NaN
  pd.merge(df1,df2, how='outer',on='id')
  
  # 왼쪽 데이터인 df1의 고유값을 기준으로 하며 왼쪽의 키는 stock_name 오른쪽의 키는 name
  pd.merge(df1,df2, how='left', left_on='stock_name', right_on='name')
  ```



### join

- merge() 함수 기반으로 만들어져 기본 작동방식은 비슷하지만 join은 행 인덱스를 기준으로 결합한다는 점에서 차이가 존재함







## replace()

- ```python
  # 모든 'math' 값들을 'science'로 바꾸기
  df.replace('math','science')
  
  # 한번에 여러개의 문자열을 치환
  df.replace({'math':'mh','english':'eng'})
  df. replace(['math','english'],['mh','eng'])
  
  # math와 english를 동시에 특정값으로 바꾸기
  df.replace(['math','english'],'Nocomment')
  
  # 숫자도 가능
  df.replace([82,77],[79,71],inplace=True)
  
  # 특정 컬럼의 값만 바꿀 때 (math score의 71값만 81로 바뀜)
  df.replace({'math score' : {71 : 81}})
  
  # 여러 컬럼의 값을 하나의 값으로 치환 ('english score' 컬럼의 95, 70과 'math score' 컬럼의 80을 모두 100점)
  df.replace({'english score':[95,70],'math score':80},'100')
  ```







## pandas 문자열 관련 함수

### str.contains()

- 검색 문자열이 포함되어 있는 경우에는 True, 아닌 경우에는 False 반환

- ```python
  len(df.tobgp.str.contains(r'(day)'))
  ```

  - df에서 **tobgp열**의 **문자열(str) 중** **r'(day)'가 포함된(contains) 행이 몇 개인지** len함수를 통해 출력

### str.extract()

- 검색 문자열에 해당하는 문자열을 추출

- ```python
  df['new'] = df.alcgp.str.extract(r'(\d+-\d\d+|\d\d\d\+)')
  ```

  - 'new' 열을 새로 만들고, df에서 **alcgp열**의 **str(문자열) 중에서** **r'(\d+-\d\d+|\d\d\d\+)'**를 **extract(추출)하여** 'new' 열에 넣겠다는 의미
  - **r'(\d+-\d\d+| \d\d\d\+)'**  
    - `\d+-\d\d+` : '숫자가 1번이상 반복' + '-문자' + '숫자 2번이상 반복'



### str.split()

- 문자열을 분할하는 함수

- ```python
  # 공백으로 분리하고 expand=True로 데이터프레임으로 만들기
  df['법정동명'].str.split(" ", expand=True).head()
  
  # - 문자로 분리하고 두개의 컬럼에 넣어주기
  insuline_clean['시작_투여량'], insuline_clean['마지막_투여량'] = insuline_clean['투여량'].str.split(' - ', 1).str
  
  # - 문자로 3번 자르기 (숫자 지정안할 때는 - 나올때마다 자름)
  insuline_clean['투여량'].str.split(' - ', 3).str # 102-134-452-135-546 인 경우 102,134,452,135-546
  ```

- ![image](https://user-images.githubusercontent.com/97875918/183459762-80ddb5b7-6b08-45a0-912a-075db46bfc57.png)



### str.replace()

- 특정 문자를 다른 문자로 교체

- ```python
  # 공백을 "_"로 대체
  df['법정동명'].str.replace(" ", "_").head()
  ```







# 일일회고



## Keep (유지할 것)

- 밥 + 운동한 시간 빼고 하루죙일 코딩한거...



## Problem (문제점, 방해 요소)

-  이번주 주말에 여행가는 것 때문에.. 옷 뭐사지 종일 고민...
-  정리할 것이 많으니 자꾸 정리는 안하고 코딩이나 하고 있음 (코 딩 조 아)



## Try (시도할 것)

- 옷을 그냥 다 사버리자 ! 고민 삭제하기
- 정리하는 거 미루지 말고 매일 꾸준히 복습하기

