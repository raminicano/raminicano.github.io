---
layout: single
title: "특성중요도"
categories: review
tag: [python, ML]
toc: true
---



# MDI (Mean Decrease Impurity)

- 트리 기반 모델에서 각 step에서 특정 피쳐에 의해 노드를 분할해 노드의 불순도를 감소시킴
  - 따라서 불순도를 크게 감소시키는데 사용된 feature들이 중요함
- sklearn의 트리기반모델은 평균불순도감소(MDI) 값을 사용하는 특성 중요도 계산을 기본적으로 제공함
- 장점
  - 빠르고 간편하게 계산이 가능하다.
- 단점
  - 높은 cardinality 특성에 높은 값을 부여하는 문제가 발생
    - 매 노드를 분할 시 cardinality가 높은 특성이 분할 기준 특성이 될 가능성이 높기 때문
    - 즉, cardinality가 너무 높은 특성이 있을 땐 믿을 만한 결과를 내지 못함







# Drop-Column Importance

- 각 특성을 사용하지 않고(drop함) 모델을 학습한 후 평가 성능을 모든 특성을 사용한 모델의 평가 성능과 비교한다.
  - 특성을 제거했을 때 평가 성능이 크게 하락했다면 해당 특성이 매우 중요한 특성이다.
- 단점
  - 이론적으로 가장 좋아보이지만 매 특성을 drop한 후 다시 fit하기 때문에 매우 느리다







# Permutation Importance

- 모델을 재학습시키지 않고 기존 모델에서 각 특성에 노이즈를 주어 모델이 해당 특성을 의사결정에 사용하지 못하게 만들었을 때 성능이 얼마나 감소하는지 확인
  - 노이즈를 주는 간단한 방법이 그 특성값들을 샘플들 내에서 섞는 것
- 장점
  - 재학습이 필요 없음
  - 모든 모델에 범용적으로 적용 가능
  - MDI보다 high cardinality 특성에 덜 치우친 결과를 낸다.
- 단점
  - 강한 상관관계가 있는 특성들이 존재할 시 잘못된 값을 낼 수 있다.







