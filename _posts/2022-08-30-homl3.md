---
layout: single
title: "머신러닝 프로젝트 과정"
categories: Hands-On-ML
tag: [ML]
toc: true
---


# MNIST

- 고등학생, 미국 인구조사국 직원들이 손으로 쓴 7만여개의 작은 숫자 이미지
- 머신러닝 분야의 'Hello World' 급
- 새로운 분류 알고리즘 나올 때마다 성능 측정 기준
- 이미 train, test 데이터 나눠놓음



# 이진 분류기 훈련

- binary classifier

  - 5가 맞음, 5가 아님 두개의 클래스로 구분함

- 사이킷런의 SGDClassifier

  - 확률적 경사 하강법(Stochastic Gradient Descent)

  - 매우 큰 데이터셋을 효율적으로 처리하는 장점

  - 훈련하는데 무작위성 사용 (재현 원할 시 random_state 지정)

  - ```python
    # 분류기 생성
    sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)
    # fit하기
    sgd_clf.fit(X_train, y_train_5)
    # 예측하기
    sgd_clf.predict([some_digit])
    ```



# 성능 측정

## 1. 교차검증을 사용한 정확도 측정

- 교차검증 구현
  - 사이킷런이 제공하는 기능보다 교차 검증 과정을 더 많이 제어해야 할수도 있음
    - 사이킷런 함수
      - 교차검증 : cross_val_score()
        - k-겹 교차검증 : 훈련 세트를 k개의 폴드로 나누고 각 폴드에 대해 예측을 만들고 평가하기 위해 나머지 폴드로 훈련시킨 모델을 사용한다.
      - 계층적 샘플링 : StratifiedKFold()
- 불균형한 데이터셋(어떤 클래스가 다른 것보다 월등히 많은 경우)을 다룰 땐 정확도를 분류기의 성능 측정 지표로 선호하지 않음

## 2. 오차 행렬

- 분류기의 성능을 평가하는 더 좋은 방법은 오차행렬을 조사하는 것
- ex. 분류기가 숫자 5의 이미지를 3으로 잘못 분류한 경우
  - 오차행렬의 5행 3열 확인
- 오차행렬 만들기
  1. 실제 타깃과 비교할 수 있도록 예측값 만들기
     - cross_val_predict() 함수 이용
       - k겹 교차 검증을 수행하지만 평가 점수를 반환하지 않고 각 테스트 폴드에서 얻은 예측을 반환
  2. 오차행렬 만들기
     - confusion_matrix() 함수 사용
       - 타겟 클래스(훈련데이터)와 예측 클래스(1번에서 만든 값) 넣고 호출
     - 행 : 실제 클래스
     - 열 : 예측한 클래스
     - ![image](https://user-images.githubusercontent.com/97875918/187427589-bdfc0f17-c546-4a68-b452-f75bf22c0920.png)

## 3. 정밀도와 재현율



- 사이킷런은 정밀도와 재현율을 포함해 분류기의 지표를 계산하는 여러 함수를 제공함

  - F1 점수 

    - 정밀도와 재현율의 조화평균

  - ```python
    from sklearn.metrics import precision_score, recall_score, f1_score #정밀도, 재현율, f1 점수
    precision_score(y_train_5, y_train_pred)
    ```

- 상황에 따라 정밀도가 중요할 수 있고 재현율이 중요할 수 있음

  - ex. 어린이에게 안전한 동영상 걸러내는 분류기
    - 좋은 동영상 많이 제외되더라도(낮은 재현율) 안전한 것들만 노출시키는(높은 정밀도) 분류기 선호함
  - ex. 감시카메라 통해 좀도둑 낮아내는 분류기
    - 진짜 도둑을 잡는 것(높은 재현율)이라면 잘못된 호출을 하는(낮은 정확도) 분류기 선호함
  - 정밀도/재현율 트레이드 오프
    - 정밀도를 올리면 재현율이 줄어들음





## 4. 정밀도/재현율 트레이드 오프

- 결정함수 사용해 각 샘플의 점수를 계산한다.

  - 정밀도 : TP / TP+FP
  - 재현율 : TP / TP+FN
  - ![image](https://user-images.githubusercontent.com/97875918/187431514-c57dedb5-582a-4fe3-bdf0-ba03c38e84d1.png)
  - 임계값이 높을 수록 재현율을 낮아지고 반대로 정밀도는 높아진다.

- ```python
  # 샘플의 점수를 얻을 수 있음
  y_scores = sgd_clf.decision_function([some_digit])
  y_scores #2164나옴
  # 임계값 지정
  threshold = 0
  y_some_digit_pred = (y_scores > threshold)
  y_some_digit_pred # True
  
  threshold = 8000
  y_some_digit_pred = (y_scores > threshold)
  y_some_digit_pred # False -> 샘플의 점수(2164)가 임계값(8000)보다 작기때문에
  ```





## 5. ROC 곡선



- 수신기 조작 특성(ROC : Receiver Operating Characteristic)
  - 거짓 양성비율(FPR)에 대한 진짜 양성비율(TPR)
  - FPR : 1 - 진짜음성비율(TNR)
  - TNR : 특이도
  - 민감도(재현율)에 대한 1-특이도 그래프
- 재현율(TPR)이 높을수록 분류기가 만드는 거짓양성(FPR)이 늘어난다.
- 곡선 아래의 면적 (AUC : area under the curve)을 측정하면 분류기들을 비교할 수 있다.
  - 완벽한 분류기는 ROC의 AUC가 1이다.





# 다중 분류

- 이진분류기

  - 두 개의 클래스를 구별

  - 로지스틱 회귀. 서포트 벡터 머신 분류기 등

  - 이진 분류기 여러개 사용해 다중 클래스를 분류하는 기법도 사용 가능

    - OvR (One-versus-the-rest 또는 OvA)

      - 이미지 분류 시 각 분류기의 결정 점수중 가장 높은 것을 클래스로 선택하는 전략
      - ex. 특정 숫자 하나만 구분하는 숫자별 이진 분류기 10개(0~9까지) 훈련시켜 클래스가 10개인 숫자 이미지 분류 시스템 생성 가능

    - OvO (One-versus-One)

      - 각 숫자의 조합마다 이진 분류기를 훈련시킴
      - ex. 0과 1구별, 0과 2구별, 1과 2구별
      - 클래스가 N개라면 분류기는 N*(N-1)/2 개가 필요
      - 장점 : 각 분류기의 훈련에 전체 훈련 세트 중 구별한 두 클래스의 해당하는 샘플만 필요함
      - ex. SVM(서포트 벡터 머신)
        - 큰 훈련 세트에서 몇개의 분류기를 훈련시키는 것 보다(OvR) 작은 훈련 세트에서 많은 분류기를 훈련시키는 쪽이 빠르므로 OvO 선호
        - 하지만 대부분의 이진 알고리즘에서는 OvR 선호

    - 사이킷런에서는 다중 클래스 분류작업에 이진분류 알고리즘 선택시 자동으로 선택됨

      - ```python
        # 자동선택
        from sklearn.svm import SVC
        # OvO, OvR 강제해서 사용하기
        from from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier 
        
        svm_clf = SVC(gamma="auto", random_state=42)
        svm_clf.fit(X_train[:1000], y_train[:1000])
        svm_clf.predict([some_digit])
        
        ovr_clf = OneVsRestClassifier(SVC(gamma="auto", random_state=42))
        ovr_clf.fit(X_train[:1000], y_train[:1000])
        ovr_clf.predict([some_digit])
        ```

      - 0~9까지의 클래스 예측

- 다항 분류기

  - 둘 이상의 클래스를 구별
  - SGD 분류기,  랜덤포레스트 분류기, 나이브 베이즈 분류기 등



# 에러 분석

- 가능성 높은 모델 찾았다 가정하고 모델의 성능을 향상시킬 방법 찾기

  - 에러의 종류를 분석하자

- 오차 행렬 살펴보기

  - ```py
    # 오차행렬 이미지로 표현
    plt.matshow(conf_mx, cmap=plt.cm.gray)
    plt.show()
    ```

  - ![image](https://user-images.githubusercontent.com/97875918/187446691-9667cefe-8dc3-48cf-92e1-a93ec538e9c6.png)

    - 배열에서 가장 큰 값은 흰색, 가장 작은 값은 검은색으로 정규화 되어 그려짐

  - 오차행렬의 대부분이 올바르게 분류되었음을 나타내는 주대각선에 분포

  - 숫자 5의 경우 조금 더 어두워 보임

    - 데이터셋에 숫자5의 이미지가 적음
    - 분류기가 숫자 5를 잘 분류하지 못함

- 그래프 에러 확인하기

  - 열에 속한 단일 행 데이터 / 각 열을 더한값

  - ![image](https://user-images.githubusercontent.com/97875918/187449552-42cacf7c-91ab-4102-8d2a-954b87ea4556.png)

  - 8열(예측)이 상당히 밝다

    - 많은 이미지가 8로 잘못 분류됨
    - 그러나 8행은 나쁘지 않음
      - 즉, 오차행렬은 반드시 대칭은 아니다.
    - 8로 잘못 분류되는 것을 줄이도록 개선하자는 인사이트 얻음
    - 개선방안
      - ex. 8처럼 보이는 숫자의 훈련데이터 많이 모아 실제 8과 구분하도록 분류기를 학습시킴
      - ex. 분류기에 도움될 만한 특성 찾기 (동심원 수를 세는 알고리즘(8은 2개 6은 1개 5는 0개))

  - 개개의 에러 분석 시 분류기가 왜 잘못되었는지 통찰 얻을 수 있음

    - 그러나 어렵고 시간 오래 걸림

    - ```python
      cl_a, cl_b = 3, 5
      X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)] # 3인데 3분류
      X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)] # 3인데 5분류
      X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)] # 5인데 3분류
      X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)] # 5인데 5분류
      
      plt.figure(figsize=(8,8))
      plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5) 
      plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5) 
      plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5) 
      plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)
      plt.show()
      ```

    - ![image](https://user-images.githubusercontent.com/97875918/187453107-d45b6236-82fe-4cea-9882-53eb93ea9496.png)

    - 왼쪽 아래 블록, 오른쪽 위 블록 잘못 분류된 case

      - 원인 : 선형모델인 SGDClassifier 사용
        - 클래스마다 픽셀에 가중치를 할당 -> 새로운 이미지에 대해 단순히 픽셀 강도의 가중치 합을 클래스 점수로 계산
        - 3과 5는 몇개의 픽셀만 다름
        - 분류기는 이미지의 위치나 회전방향에 매우 민감
          - 이미지를 중앙에 위치 + 회전되어 있지 않도록 전처리



# 다중 레이블 분류

- 분류기가 샘플마다 여러개의 클래스를 출력해야할 때도 있다.

  - ex. 얼굴 인식 분류기
    - 같은 사진에 여러사람 등장

- 다중 레이블 분류 시스템

  - 여러개의 이진 꼬리표를 출력하는 분류 시스템
  - ex. 분류기가 앨리스와 찰리가 있는 사진을 봄
    - 분류기는 앨리스, 밥, 찰리 세 얼굴을 인식하도록 훈련됨
    - [1, 0, 1]
    - 앨리스 있음, 밥 없음, 찰리 있음

- ```python
  from sklearn.neighbors import KNeighborsClassifier
  
  y_train_large = (y_train >= 7)
  y_train_odd = (y_train % 2 == 1)
  y_multilabel = np.c_[y_train_large, y_train_odd] # 두 배열을 열로 합치기
  
  # Kn 분류기는 다중 레이블 분류 지원
  knn_clf = KNeighborsClassifier()
  knn_clf.fit(X_train, y_multilabel)
  
  knn_clf.predict([some_digit]) # 5인 데이터
  # 출력 결과 False, True
  ```

- 다중 분류기 평가하는 방법

  - ex. 각 레이블의 F1 점수(또는 특정 이진 분류 지표 사용) 구해 평균 점수 계산
  - 레이블에 가중치 두기
    - 레이블에 클래스 지지도(타깃 레이블에 속한 샘플 수)로 가중치 주는 것





# 다중 출력 분류

- 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화한 것

- ex. 이미지에서 잡음을 제거하는 시스템

  1. 잡음이 많은 숫자이미지를 입력으로 받기

  2. 깨끗한 숫자 이미지를 픽셀의 강도를 담은 배열로 출력 (ex. MNIST 데이터)

  3. 다중 출력 분류 시스템인 이유

     1. 1픽셀 = 1레이블
        - 여러 개 있음 -> 다중 레이블
     2. 레이블이 가질 수 있는 값
        - 0~ 255개 -> 다중 클래스

     

  ```python
  noise = np.random.randint(0, 100, (len(X_train), 784))
  X_train_mod = X_train + noise
  noise = np.random.randint(0, 100, (len(X_test), 784))
  X_test_mod = X_test + noise
  y_train_mod = X_train
  y_test_mod = X_test
  
  some_index = 0
  plt.subplot(121); plot_digit(X_test_mod[some_index]) # 노이즈 있는 x테스트 데이터
  plt.subplot(122); plot_digit(y_test_mod[some_index]) # 노이즈 없는 x테스트 데이터
  plt.show()
  
  knn_clf.fit(X_train_mod, y_train_mod) # 노이즈 있는 x훈련 데이터, 노이즈 없는 x훈련 데이터
  clean_digit = knn_clf.predict([X_test_mod[some_index]]) # 노이즈 있는 테스트 데이터로 예측
  plot_digit(clean_digit)
  ```

  





