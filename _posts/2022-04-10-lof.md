---
layout: single
title: "LOF (Local Outlier Factor)"
categories: AI
tag: [인공지능, 이상탐지, 머신러닝, 딥러닝]
toc: true

---


이상치 탐지 영역의 알고리즘인 Local Outlier Factor(LOF)에 대해 알아보자. 먼저 이상탐지가 무엇이고 왜 필요한지 보고 국소(local)영역에서 이상치를 탐지하는 LOF 알고리즘을 알아보는 순서대로 작성하였다.

# Anomaly Detection?
Anomaly Detection은 ML의 Unsupervised Learning의 영역으로 주어진 데이터로 하여금 이상치를 탐지하는 방법들의 집합으로 정의할 수 있다. <br>

<u><b>예시 : Fraud Detection</b></u>
정상/사기에 대한 이진분류를 생각했을 때 두가지 문제에 직면한다.

1. 정상의 경우보다 사기가 극단적으로 적은 상황
    - 분류 문제를 풀기 위해 ML의 Supervised Learning 알고리즘을 이용
    - 그러나 SL은 주어진 데이터에서 패턴을 찾고 이에 대한 예측결과를 제공하다 보니 데이터가 적응 영역에서 성능이 떨어짐
2. '사기'라는 event를 정의하기 어려운 상황
    - 판촉 광고를 문자/메일/전화 등으로 받았을 경우 때로는 Spam보다는 Ham일 수 있어 사기/스팸 등으로 정의를 내려야 하는데 쉬운일이 아님
<br>

이때 Anomaly Detection을 적용하는게 도움이 될 수 있다.
1. 단순히 일반적인 패턴이 아닌 <b>데이터를 분류</b>하면 되는 문제로 바꾸어 해결한다.
2. Anomaly Detection은 라벨을 정의할 필요가 없으니 <b>데이터 패턴이 특이</b>한 것을 사기/스팸으로 바꾸어 생각하면 된다.

<br>
<br>
<br>
<br>

# LOF 란?

- <b>밀도 기반의 이상탐지 방법</b>으로 local을 나누어 local의 밀도를 이용해 각 point마다 factor를 부여하여 이상치를 탐지하는 방법
- LOF는 각각의 관측치가 데이터 안에서 얼마나 벗어나 있는가에 대한 정도를 나타낸다.
- 모든 데이터를 전체적으로 고려하는 것이 아니라 해당 관측치의 주변 데이터를 이용해 <b>국소적 관점</b>으로 이상치 정도를 파악한다.
<img width="696" alt="image" src="https://user-images.githubusercontent.com/97875918/230825025-f771c442-66cd-46ab-be58-78cb01ec026c.png">

- O2가 O3보다 주변 point들과의 거리를 보면 더 짧지만 국소적인 밀도 관점에서 보면 abnormal score를 구했을 때 O2가 O3보다 크게 끔 만드려는 것이 LOF의 개념이다.
- 즉, 데이터 안에서 <b>밀도 기반의 각 군집들을 생성</b>하고 <b>해당 군집에서 얼마나 떨어져 있는 지를 확인</b>해 abnormal score를 만들어 outlier를 제거하는 개념이다.
- 밀도기반의 이상치 탐지 방법이기 때문에 주변 데이터를 몇개까지 고려할 것인가를 나타내는 k 하이퍼 파라미터만 결정하면 된다.
- 단점 : 크기가 큰 데이터에서는 계산량이 많아 사용하기 어렵다.



<br>
<br>
<br>
<br>


# 주요 개념

1. the distance between objects p and q
    - d(p, q) : 관측치 p와 q의 거리
2. k-distance of an object p 
    - k-distance(p) : 관측치 p와 k번째로 가까운 이웃(포인트)의 거리
3. k-distance neighborhood of an object p
    <img width="635" alt="image" src="https://user-images.githubusercontent.com/97875918/230827030-88ada281-ddb4-44a5-abb8-30812c0d2ae0.png">

    - Nk(p) : 관측치 p의 k-distance(p)보다 가까운 이웃의 개수
    - 관측치 p를 중심으로 k-distance로 원을 그릴 때 원안에 들어와 있는 point의 갯수
4. Reachability Distance of an object p w.r.t object
    - Reachability Distance : 주어진 데이터로부터 k-neighborhood의 데이터 내에 있을 경우 거리를 같게, 아닌 경우는 실제 거리를 측도하는 방법이다.
    <img width="344" alt="image" src="https://user-images.githubusercontent.com/97875918/230827968-d1c44cd3-ab2e-4586-b6ac-5ea29df3ba2f.png">
    - reach-distance : O와 가까운 point는 3-distance(O)값을 가지고 O와 멀다면 distance(실제거리)를 갖는다.
    <img width="692" alt="image" src="https://user-images.githubusercontent.com/97875918/230827652-a1c51c13-d28e-4886-8a93-32a3eeffe18e.png">
    - 관측치 p가 o에서 멀다면 : 관측치 p와 o의 실제거리
    - 관측치 p가 o에서 가깝다면 : 관측치 o의 k-distance
5. Local Reachability density(lrd) of an object p
    <img width="573" alt="image" src="https://user-images.githubusercontent.com/97875918/230829536-b7f39e9f-a569-48b4-b5a5-d02363695297.png">
    - N <sub>k</sub>(Y) : 데이터 Y 근방의 k개의 데이터라는 의미
        - 절대값의 경우 : k보다 크거나 같은 값을 가질 수 있다.
        - ex) k=2, Y 에서 가까운 거리의 점이 1,2,2,2,2 순이라고 하면 해당 값은 5가 됨
    - RD를 산출하는 부분 : 기준 데이터 Y 근방에 있는 어떤 데이터 X<sub>j</sub>를 산출하는 기준점이 X<sub>j</sub>이다.
        - 즉 Y는 Y와 가까운 X<sub>j</sub>들 사이에서 얼마나 떨어져 있는지를 측도하는 것이다.
        - Y가 Y근방에 있는 데이터들의 공간에서 동떨어져 있을 수록 분모의 크기가 커져 LRD는 작은 값을 얻는다.
    - <u><b>예시1</b></u> k=4를 기준으로 했을 때
        <img width="605" alt="image" src="https://user-images.githubusercontent.com/97875918/230830704-09056e8a-c905-46d9-b010-3f6d0d6ec602.png">
        - Case 1 : 밝은 보라색인 이웃점들의 근방과의 거리 대비 가까움
        - Case 2 : 위 경우보다 상대적으로 거리가 멂
        - Case1의 LRD가 Case2 대비 큰 값을 갖게된다.
    - <u><b>예시2</b></u> k=3를 기준으로 했을 때
        <img width="703" alt="image" src="https://user-images.githubusercontent.com/97875918/230831886-07db1abd-4296-41c0-811d-0f44c162eda4.png">
        - 예시 1 : 관측치 p의 3-이웃이 가깝게 있음, 이웃 O<sub>i</sub>(i=1,2,3)의 reach-dist3(p,O<sub>i</sub>)가 작음
            - LRD3(p)는 큰 값이 산출됨
        - 예시 2 : 관측치 p의 3-이웃이 멀게 있음, 이웃 O<sub>i</sub>(i=1,2,3)의 reach-dist3(p,O<sub>i</sub>)가 큼
            - LRD3(p)는 작은 값이 산출됨
    - 정상(밀도가 높은 경우) : LRD가 커짐
    - 이상치 : LRD가 작아짐
6. Local outlier factor(LOF) of an object p
    <img width="595" alt="image" src="https://user-images.githubusercontent.com/97875918/230849422-aa1644e1-ba8f-4ea3-9539-5fa975924ca0.png">
    - 측도하고자하는 데이터 Y 대비 k근방 데이터들의 LRD가 얼마나 작은가를 측도한다.
    - 이상치일수록 LOF은 커짐
    - 밀도가 높은 군집의 경우 : lrd(p)와 lrd(O)가 둘 다 클 것이기 때문에 1에 가까운 숫자가 됨
    - 밀도가 낮은 군집의 경우 : 1보다 큰 LOF을 가짐
        - LOF 값이 크다는 것은 주변 데이터들이 흩어짐 정도보다 훨씬 많이 떨어져 있음을 의미한다.
        - LOF 크기가 클 수록 Outlier임을 의미한다.
        - 1보다 큰 값을 Outlier로 분류하고 값이 클수록 Outlier정도가 심함을 의미한다.
    - <u><b>예시</b></u> 
        <img width="684" alt="image" src="https://user-images.githubusercontent.com/97875918/230851265-c8a305ea-30be-4638-b8f8-f3f4dd6022e7.png">



<br>
<br>
<br>
<br>