---
layout: single
title: "CH3 Classification : Basic Concepts and Techniques"
categories: coding
---



# Basic Concepts

## Classification

- 사물을 **범주(클래스)**로 분류한다.

- 개념

  - **데이터** : 인스턴스 집합으로 각 인스턴스는 (x,y)로 표시된다.

    - x : 인스턴스를 설명하는 속성 값 집합 (유형에 대한 제한 **없음**)
      - 모든 속성이 classification과 관련이 있지는 **않다**.
    - y : 인스턴스의 클래스 레이블 (**범주형**이어야 함)

  - **모델** : x와 y에 대한 추상적인 표현

    - x를 취하여 y의 예측값을 출력하는 함수 f(x)로 표현됩니다.

    - f(x) = y일 경우 모형 f(x)는 인스턴스(x, y)를 올바르게 분류한 것



## General Framework for Classification

- Classification

  - 레이블이 지정되지 않은 인스턴스에 **레이블**을 할당하는 작업

- Classifier

  - 분류를 수행하는 데 사용되는 **모델**

- Training set

  - 모델을 만드는 데 사용되는 주어진 인스턴스 집합
  - 각 인스턴스의 클래스 레이블뿐만 아니라 속성 값 포함

- Learning algorithm

  - 트레이닝 집합이 주어진 분류 모델을 학습하기 위한 체계적인 접근

- Induction

  - 트레이닝 데이터에서 분류 모델을 구축하기 위해 학습 알고리즘을 사용하는 프로세스

- Deduction

  - 아직 분석되지 않은 인스턴스에 모델을 적용하여 클래스 레이블을 예측하는 프로세스

    

## Performance of a Classifier

- 예측 레이블을 인스턴스의 실제 레이블과 비교하여 평가할 수 있다.

- 단, 트레이닝과 테스트 집합은 서로 **독립적**이어야 한다.

  - 모델은 이전에 **접한 적이 없는** 인스턴스의 클래스 레이블을 정확하게 예측해야 한다(즉, **좋은 일반화 성능**).

  - 따라서, 훈련 집합의 성능은 일반화 성과를 측정하는 좋은 척도가 아니다.

    

## Evaluation Metrics

- Confusion matrix
  - 분류기의 성능 평가 결과를 설명하는 표





# Decision Tree Classifier

- 인스턴스의 속성에 대해 **주의 깊게 만들어진 일련의 질문**을 하여 분류 문제를 해결한다.

  - 우리가 그것의 클래스 레이블을 확정할 수 있을 때까지
  - 일련의 질문과 가능한 답변은 **의사결정 트리**라고 불리는 계층 구조로 구성된다.
  - 우리는 어떻게 그 속성들을 결정할 수 있을까?

  

## Structure of Decision Tree

- Root node
  - 0개 이상의 발신 링크
- Internal node
  - 정확히 1개의 수신링크
  - 2개 이상의 발신 링크
- Leaf(terminal) node
  - 정확히 1개의 수신링크
  - 발신 링크 없음
- **Attribute test condition**
  - 루트와 내부 노드가 포함된다.
  - 가능한 각 결과는 노드의 자식 하나와 정확히 연관되어 있다.



## Classifying an Unlabeled Instance

- 일반 절차

  1. 루트 노드에서 시작
  2. 속성 시험 조건을 적용하고 시험 결과에 따라 적절한 분기를 따른다.
  3. 리프 노드에 도달하면 노드에 연결된 클래스 레이블을 인스턴스에 할당한다.

  

## Algorithms to Build a Decision Tree

- 특정 데이터셋에서 **많은** 의사 결정 트리를 구축할 수 있다.
  - 그러나 최적의 것을 찾는 것은 계산적으로 **비용**이 많이 든다.
  - 검색 공간의 지수 크기로 인해
- 효율적인 알고리즘이 개발되어 **합리적인 시간** 내에, 비록 최적이지는 않지만, **합리적**으로 정확한 의사 결정 트리를 유도한다.
  - 이러한 알고리즘은 일반적으로 의사 결정 트리를 하향식으로 성장시키기 위해 **greedy** 전략을 사용한다.
    - 최선의 애트리뷰트를 선택한 뒤에 나중에 잘못 선택했더라도 뒤로 돌아갈 수 없음
  - 트레이닝 데이터를 분할할 때 어떤 속성을 사용할지에 대해 일련의 **로컬 최적 결정**을 내림
- 예
  - Hunt의 알고리즘(많은 현재 의사 결정 트리의 기반)
  - ID3(+ information gain), C4.5(+ numerical attributes), CART(+ regression)



## Hunt's Algorithm

1. 처음에는 단일 루트 노드로 시작한다.
   - 루트 노드가 **모든** 트레이닝 인스턴스와 연결되어 있다.
2. **분할 기준**을 사용하여 각 노드 분할
   – 분할 기준은 노드에 대한 속성 테스트 조건을 결정
   – 속성 테스트 조건의 각 결과에 대한 하위 노드 생성
   – 테스트 결과에 따라 자식에게 인스턴스를 배포
3. **정지 기준**이 충족되면 분할 중지
   – 마지막으로, 각 리프 노드에는 노드와 관련된 트레이닝 인스턴스에서 가장 자주 발생하는 클래스 레이블이 할당된다.



## Design Issues of Decision Tree Induction

알고리즘을 구현하기 위해서는 두 가지 핵심 이슈가 해결되어야 한다.

1. **분할 기준**은 무엇입니까?
   - 각 노드에서 노드와 관련된 트레이닝 인스턴스를 분할할 **속성**을 선택해야 한다.
   - 분할 기준은 테스트 조건으로 선택한 속성과 트레이닝 인스턴스가 하위 노드에 배포되는 방법을 결정한다.
2. **정지 기준**은 무엇입니까?
   - 노드에 연결된 모든 트레이닝 인스턴스가 동일한 클래스 레이블을 가질 때 노드 분할을 중지할 수 있다.
   - 그러나 노드 분할을 훨씬 **이전에** 중단해야 하는 이유가 있다.
   - 이 프로세스를 조기 종료라고 하며 나중에 설명한다.



## Attribute Test Conditions

- 이진 분할
  - 속성의 모든 값을 **두** 그룹으로 분할
- 다방향 분할
  - 속성의 **각** 값 또는 범위에 대한 노드 생성

## Selecting an Attribute Test Condition

- 속성 테스트 조건의 **적합성**을 결정하는 데 사용할 수 있는 많은 측정값이 있다.
- 이 방법은 트레이닝 인스턴스를 **더 순수한** 하위 노드로 분할하는 속성 테스트 조건에 우선 순위를 부여합니다.
  - **순수 노드**: 동일한 클래스의 모든 트레이닝 인스턴스를 가집니다.
  - 불순한 노드: 여러 클래스의 트레이닝 인스턴스를 포함합니다.
  - 불순한 노드가 트리의 깊이를 증가시키고 더 큰 트리는 **모델 과적합**에 더 취약하기 때문

## Impurity Measures for a Single Node

**노드의 불순물** : 노드에 속하는 데이터 인스턴스의 클래스 레이블이 얼마나 다른지 측정한다.
**표기법**
– t: 노드
– pi(t): 클래스 노드에서의 훈련 인스턴스의 상대적 빈도
– c: 총 클래스 수

1. ### Entropy

   - 값의 "정보" 또는 "불확실성"의 평균 수준
     - t에서 값을 관측하여 얻을 수 있는 예상 정보량

2. ### Gini Index

   - 값 사이의 "불평등성" 수준
     - 모든 값이 동일할 때 **최소화**됨(즉, 완벽한 동일성)
     - 가능한 모든 값이 다를 때 **최대화**

   - 엔트로피보다 지니가 더 빠름(성능은 비슷)

3. ### Classification Error

   - 가장 빈도가 높은 클래스에 속하지 않는 인스턴스의 비율
     - max[pi(t)] : 가장 빈도가 높은 부류에 속하는 사례의 비율

4. ### Comparison among Impurity Measures

   - 3번 방법은 그래프가 연속적이지 않아 부자연스럽다.
   - 관측내용
     - 클래스 분포가 균일할 때 모든 측정값이 **최대화**
     - 모든 인스턴스가 단일 클래스에 속할 때 모든 측정값이 **최소화**


## Collective Impurity of Child Nodes

- 노드 v를 k개의 하위 노드로 분할하는 속성 테스트 조건을 고려합니다.
  - N: v와 관련된 교육 인스턴스 수
  - N(vj) : vj와 관련된 교육 인스턴스 수
  - I(vj) : vj의 불순물
- 그러면 다음과 같이 {v1, ... , vk}의 집단 불순물을 계산할 수 있다.

## Finding The Best Attribute Test Condition

- 최적의 속성시험 조건을 찾기 위해서는 속성시험 조건의 **우수성**을 판단해야 한다.
- 시험조건의 좋고 나쁨은 어떻게 판단할 수 있는가?
  - 분열 후 불순물이 얼마나 **감소**하는지 측정한다.
  - 감소폭이 **클수록** 시험조건이 좋아진다.
- 이를 위해 다음과 같이 정보이득을 계산한다.
  - I(부모): 상위 노드의 불순물(즉, 분할 전)
  - I(자녀): 하위 노드의 불순물(즉, 분할 후)
- 지니인덱스 관련 공식
  1. 부모노드의 복잡도를 계산한다.
  2. 자식노드의 복잡도 계산
     - N1에서 1- 제곱(yes) - 제곱(no) 구하고 N2의 1- 제곱(yes) - 제곱(no) 구하기
     - 두개의 값에 각 가중치 곱하기 (ex.N1의 가중치 : N1의 총 갯수(no와 yes합한 거) / 전체 갯수(N1과 N2 다 더한 거))
     - 가중치를 곱한 값을 다 더하기
  3. 부모노드 - 자식노드 의 값 도출

## Binary Splitting of Numeric Attributes

- 기본적인 방법
  1. 연간 수입에 따라 교육 인스턴스 **정렬**
  2. 두 값 사이의 **중간점**을 후보 분할 위치로 선택
  3. **각** 후보 분할 위치에 대한 정보 이득 계산
  4. **가장 높은** 정보 이득을 얻는 위치 선택

## Characteristics of Decision Tree Classifiers

1. #### **적용가능성**

   - 클래스 및 속성의 분포가 있는 **어떤** 데이터 세트에도 적용 가능
     - 클래스가 어느 한쪽으로 데이터가 치우쳐져 있어도 괜찮다.
   - 범주형 데이터와 숫자 데이터 **모두**에 적용 가능
   - 또한 변경 없이 **멀티 클래스** 문제를 처리할 수 있다.
   - 유도된 나무는 상대적으로 해석하기 **쉽다**.

2. #### 표현력

   - 임의의 함수 y = f(x)를 인코딩할 수 있습니다. 여기서 x와 y는 **이산값**입니다.

3. #### 계산 효율성

   - 많은 결정 트리 유도 알고리즘은 **체험적인** 접근 방식을 사용한다.
     - 탐욕스럽고 하향식이며 재귀적인 분할 전략
   - 그러한 기법은 훈련 세트 크기가 매우 큰 경우에도 상당히 좋은 의사 결정 트리를 **신속하게** 구성한다.
   - 또한 테스트 인스턴스를 분류하는 속도가 매우 **빠릅니다**.

4. #### 결측값 처리

   - 결측값을 **추정하여** 하위 노드에 데이터 인스턴스 할당
     - 누락되지 않은 다른 속성 값을 기반으로 합니다.
   - 또는 결측값이 있는 인스턴스 **제외**
   - decision 트리는 기본적으로 missing value존재 시 못나눈다. 처리가 곤란하다.

5. #### 관련 없는 속성 처리

   - 속성이 분류 작업에 유용하지 않으면 **관련이 없다**.
   - 많은 수의 관련 없는 속성이 있는 경우, 그 중 일부가 **실수로** 분할되도록 선택될 수 있습니다.
     - 무작위 확률로 관련 속성보다 더 나은 이득을 제공하는 경우
   - 그러므로 의사결정 트리는 관련 없는 속성이 많을 경우 성능이 **저하될** 수 있다.

6. #### 중복 속성 처리

   - 속성이 다른 속성과 강하게 상관되는 경우 **쓸모가 없다**.
   - 중복 속성은 순도가 비슷하므로 분할을 위해 **하나만** 선택됩니다.
   - 따라서 의사 결정 트리는 중복 속성의 존재를 **처리할 수 있다**.

7. #### 직선 분할 사용

   - 시험 조건에는 단일 속성만 포함되므로 결정 경계가 **직선**(즉, 좌표 축에 평행)이다.
     • **결정 경계**: 다른 클래스의 영역 사이의 경계
   - 이는 의사 결정 트리의 표현력을 심각하게 **제한한다**.

8. #### 불순물 방법의 선택

   - 의사 결정 트리 분류기의 성능에 **거의 영향을 미치지 않는** 경우가 많다. (어떤 분류방법을 사용하느냐는 중요하지 않음)
     - 많은 측정이 서로 상당히 일치하기 때문에
   - 대신 정지 조건이 최종 트리에 **더 큰 영향**을 미친다.(중요한 건 어디까지 내려갈 것이냐)
     - 왜냐하면 그것은 나무의 과적합과 관련이 있기 때문이다.







# General Issues of Classification Models

1. 모델 과적합
   - 왜 과적합이 일어나는가?
   - 너무 모델의 자유도를 허락하면 안됨
2. 모델 선택
   - 어떻게 하면 적절한 수준의 복잡성을 가진 모델을 선택할 수 있을까?
   - 오버피팅을 피하면서 모델 잘 선택하기
3. 모델평가
   - 선택된 모델의 일반화 성능을 어떻게 추정할 수 있습니까?
   - 선택된 모델이 실전에서의 성능 예측
4. 초 매개 변수의 존재
   - 하이퍼 파라미터의 값은 어떻게 선택할 수 있습니까?
   - 파라미터는 모델이 훈련데이터를 통해 학습해서 얻어낸 숫자지만 하이퍼파라미터는 사람이 줘야하는 것

## 1. Model Overfitting

- 모델 과적합
  - 모형이 교육 데이터에 잘 적합하더라도 일반화 **성능이 좋지 않은** 경우 (다른 데이터에 적용하면 별로)
    - 즉, test데이터의 성과 < training데이터의 성과
- 모델 언더피팅
  - 교육 데이터**에서도** 모델의 성능이 저하된 경우
    - 모델이 너무 단순하고 실제 패턴을 완전히 나타낼 수 없다.

### Reasons for Model Overfitting

- 모형이 **지나치게 복잡**하기 때문에
  - 따라서, 그것은 교육 데이터에서 **매우 구체적인** 패턴을 포착한다.
  - 그러나 그것은 전체적인 데이터에서 관계의 **진정한** 본질을 배우는 데 실패한다.

### Two Major Factors Affecting Overfitting

##### 1. 트레이닝 사이즈 제한

- 교육 세트는 전체 데이터의 **제한된** 측면만 제공할 수 있다.
- 따라서, 훈련 세트에서 학습된 패턴은 전체 데이터의 실제 패턴을 완전히 나타내지 못할 수 있다.
- 이 경우 트레이닝 데이터의 크기를 늘리면 과적합이 줄어들 수 있다.

##### 2. 높은 모델 복잡성

- 일반적으로, 더 복잡한 모델은 데이터에서 복잡한 패턴을 더 잘 표현할 수 있다.
- 그러나 지나치게 복잡한 모델은 일반화가 잘 되지 않는 훈련 세트에서 **특정 패턴**을 학습하는 경향이 있다.
- 따라서 복잡도가 **높은** 모델은 과적합되기 쉽다.

### How Can We Measure Model Complexity?

- 한 가지 접근 방식: 교육 세트에서 유추해야 하는 "**모델 매개변수**"의 수를 계산합니다.
  - **Decision Tree** : 속성 테스트 조건 수(= 노드)
  - **선형 회귀 분석**: 계수 수
  - **신경망** : 가중치 수 (= 뉴런과 층)
- 파라미터의 수는 **많지만** 교육데이터는 **적은** 경우
  - 학습 알고리즘이 **무작위 확률**로 평가 메트릭을 최대화하는 파라미터의 비논리적인 조합을 선택할 가능성이 높다.





## 2. Model Selection

- 보이지 않는 인스턴스에 대해 **잘 일반화될** 것으로 예상되는 **적절한** 수준의 복잡성을 가진 모델을 선택하는 프로세스
- 따라서 트레이닝 에러는 모델 선정의 유일한 기준으로 확실하게 **사용할 수 없다.**
- 모델 선택을 위한 세 가지 접근 방식에 대해 논의한다.
  - 의사 결정 트리에 대한 하나의 일반적인 접근 방식과 두 가지 특정 접근 방식

### Using a Validation set

- 모델 선택을 위한 일반적인 접근 방식
  1. 주어진 교육 세트 D.train을 D.tr 및 D.val로 분할
     - (ex) D.tr = D.train 2/3 및 D.val = D.train 1/3
  2. D.tr에서 교육받은 모든 모델의 경우 D.val을 사용하여 일반화 성능을 추정한다.
     - D.val의 오류율을 **유효성 검사 오류율**이라고 합니다. (만들어진 모델의 성능을 측정하는 기준이 D.val)
  3. 검증 오류율이 가장 낮은 모델을 선택한다.
     - validation error는 교육 오류율보다 일반화 성능을 나타내는 더 나은 지표이다.
- 제한사항 : D.tr, D.val 사이즈에 민감합니다.
  - D.tr이 너무 작으면, 형편없는 모델의 학습으로 이어질 수 있습니다.
    - 교육 세트가 작을수록 전체 데이터의 대표성이 떨어지기 때문에
  - D.val이 너무 작으면 유효성 검사 오류율을 신뢰할 수 없을 수 있습니다.
    - 적은 수의 인스턴스에 걸쳐 계산되기 때문에

### Pre-Pruning (Only for Decision Trees)

- 전체 교육 데이터에 완벽하게 맞는 완전히 성장한 트리를 생성하기 **전에** 트리 성장 알고리즘 중지
- 이를 위해서는 보다 제한적인 정지 조건을 사용해야 한다.
  - (ex) 예상 이득이 특정 임계값 아래로 떨어질 경우 리프 노드 확장 중지 (내가 나눴을 때 얻을 수 있는 information gain이 얼마 안되면 나눌필요 x)
- 장점
  - 지나치게 복잡한 하위 트리를 생성하여 교육 데이터를 과도하게 적합시키는 것을 방지한다.
- 단점
  - 유의한 이득을 얻지 못하더라도 후속 분할을 통해 더 나은 하위 트리가 생성될 수 있다. (좀만 더 가면 엄청 큰 이득인데 포기함)

### Post-Pruning (Only for Decision Trees)

- 의사결정 트리를 최대 크기로 키운 다음 완전히 성장한 트리를 상향식으로 **다듬는다.**
  - 특정 임계값을 초과하여 일반화 오류 추정치의 추가 개선이 관찰되지 않는 경우 종료
- 트리밍 어프로치 1: **서브트리 교체**
  - 하위 트리를 하위 트리의 인스턴스(instance)의 다수 클래스에서 클래스 레이블이 결정되는 새 리프 노드로 바꾼다.

- 트리밍 접근 방식 2: **서브트리 올림**
  - 하위 트리를 하위 트리에서 가장 자주 사용되는 분기로 바꾼다.
- 장점
  - 미리 손질하는 것보다 더 좋은 결과를 주는 경향이 있습니다.
    - 나무 생육의 조기 종식을 겪지 않기 때문이다.
- 단점
  - 전체 트리를 키우는 데 필요한 추가 계산이 낭비될 수 있다.



## 3. Model Evaluation

- 여기서는 선택한 모델의 **일반화 성능**을 추정하는 방법에 대해 논의한다.
  - 즉, D.train 외부에서 측정되지 않은 인스턴스에 대한 성능
- validation error는 측정되지 않은 인스턴스의 성능에 대한 **편향된** 지표라는 점에 유의한다.
  - 분류모델 선정에 **사용**되었으므로
  - 모델 선택에 validation error를 사용하는 경우, 결과 모델은 유효성 검사 세트의 오류를 최소화하기 위해 **의도적으로** 선택될 것이다.
  - 따라서 validation error는 실제 일반화 오류율을 **과소평가**할 수 있으므로 모델 평가에 안정적으로 사용될 수 **없다.**
- 모델 평가를 위한 **올바른** 접근 방식
  - 모델 선택 단계에서 **사용되지 않은** 데이터 세트에서 학습된 모델의 성능 평가
  - 전체 세트 D를 두 개의 분리된 하위 세트 D.train 및 D.test로 분할합니다.
    - D.train: 모델 교육 및 선택(예: D.train = D.tr + D.val)
    - D.test: 선택한 모형의 일반화 성능 추정
- D를 D.train과 D.test로 구분하고 일반화 성능을 추정하는 두 가지 방법
  - 홀드아웃 방식
    - 단점 : 1. 테스트 집합을 어떻게 선택하느냐에 따라 예측성능이 바뀜(한번 측정하고 끝남) 2. test 데이터가 속하지 않은 데이터가 있을 수 있음 (fully하게 사용되지 못함)
  - 교차 검증

### Holdout Method

- 기본 단계
  1. D를 **무작위**로 D.train 및 D.test로 분할
  2. D.train에서 분류 모델을 교육하고 선택한다.
  3. **D.test**에서 모형의 일반화 성능 추정
- D.Train 및 D.Test에 대한 데이터 비율
  - 일반적으로 분석가의 재량에 따른다.
    - 예: D.train:D.test = 3:1
  - D.train이 작으면 부적절하게 학습된 모델을 얻을 수 있다.
  - D.test이 작으면 신뢰도가 낮은 성능 추정치를 얻을 수 있습니다.
- 랜덤 서브샘플링(또는 반복 홀드아웃 방법)
  - 홀드아웃 방법을 **여러 번** 반복합니다.
  - 일반화 성능의 분산을 이해하는 데 사용할 수 있는 오류 비율의 분포를 얻을 수 있다.

### Cross-Validation

- 교육 및 테스트 모두에 D의 **모든** 인스턴스를 사용하는 것을 목표로 한다.
- 예: 3배 교차 검증
  1. D를 세 개의 동일한 크기의 부분 집합(S1, S2, S3)으로 랜덤하게 분할
  2. S2 + S3를 사용하여 모델을 교육하고 선택한 후 S1에서 모델을 테스트
  3. S1+S3를 사용하여 모델을 교육하고 선택한 후 S2에서 모델을 테스트
  4. S1+S2를 사용하여 모델을 교육하고 선택한 후 S3에서 모델을 테스트
  5. 세 가지 결과를 **평균화**하여 전체 일반화 오차를 구함

### k-Fold Cross Validation

1. 데이터 세트 D를 k개의 동일한 크기의 파티션(또는 접힘)으로 분할
2. i번째 수행 중 (i = 1, 2, …k)
   - k개의 접힌 부분 중 하나를 D.test(i)로 선택하여 테스트합니다(즉, 1/k의 D).
   - 나머지는 교육 및 선택을 위한 D.train(i)로 사용합니다(즉, (k – 1)/k of D).
   - D.train(i)을 사용하여 모델 교육 및 선택
   - D.test(i)에 모델을 적용하여 검정 오류율 Ei를 구합니다.
3. 마지막으로, 평균 테스트 오류율 E를 다음과 같이 계산합니다.

**관측내용**

- 데이터의 모든 인스턴스는 정확히 한 번 테스트에 사용된다.
- 데이터의 모든 인스턴스는 정확히 (k – 1)회 교육에 사용된다.

### The Right Choice of k

- 문제의 여러 특성에 따라 다름

  - Small k: 모든 실행 시 더 작은 교육 세트(E의 더 큰 추정치)

  - Large k: 모든 실행에서 더 큰 교육 세트(편향 감소 추정치 E)

- **Leave-One-out** 접근방식
  - k = N(데이터 크기)인 극단적인 경우
  - 장점: 교육에 최대한 많은 데이터 활용
  - 단점: 계산 비용이 많이 든다.(이 절차는 N회 반복)
- 대부분의 실제 적용에서 k는 5에서 10 사이
  - 각 폴드는 전체 데이터의 80%~90%를 교육에 사용하므로 합리적

### Notes on k-Fold Cross-Validation

- k-fold 교차 검증에서는 각 런에서 **다른** 모델을 학습합니다.
  - 그런 다음, 우리는 E를 얻기 위해 k개의 다른 모델의 오류율을 평균한다.
  - 따라서 E는 k 모델의 오류율을 나타내지 **않는다**.
- 대신 오류율 E는 **모델 선택 접근법**의 **예상** 일반화 오류율을 반영한다.
  - D.train(i)과 동일한 크기의 교육 세트에 적용할 경우
- 홀드아웃 방식으로 계산된 오류율과 다르다.
  - D.Train을 통해 학습된 특정 모델과 정확히 일치한다.
  - 홀드아웃 메서드는 기대값이 아니라 실제 그 모델의 성능이고 k-fold는 모델들이 다 다르기에 그 전략자체의 평균 기대치

## 4. Presence of Hyper-Parameters

- 하이퍼 파라미터
  - 분류 모델을 학습하기 **전에** 결정해야 하는 학습 알고리즘의 매개 변수
  - (ex) 매개변수의 "수"
    - Decision Tree : 속성 테스트 조건 수(= 노드)
    - 선형 회귀 분석: 계수 수
    - 신경망 : 가중치 수 (α 뉴런과 층)
- 하이퍼 파라미터 선택
  - 모델을 선택하는 동안 하이퍼 파라미터의 값을 **결정해야** 한다.
  - 이는 앞에서 설명한 교차 검증 접근 방식을 통해 효과적으로 달성될 수 있다.

### Approach

1. ### Simple Approach

   - 기본 단계
     - p를 하이퍼파라미터라고 한다.
     - p의 후보 값 집합을 구성한다.
     - D.train을 D.tr 및 D.val로 파티션 분할
     - 각 후보 값 pi에 대해 D.tr에서 모델을 학습하고 이 모델을 D.val에 적용하여 검증 오류율을 구한다.
     - 검증 오류율이 가장 낮은 모델을 선택

2. ### Cross-Validation

   - 기본 단계
     - D.Train을 k폴드로 분할
     - 각 실행에서 각 후보 값 pi에 대해 하나의 폴드를 유효성 검사를 위해 D.val로 사용하고 나머지 폴드는 모델을 학습하기 위해 D.tr로 사용합니다.
     - 모든 k폴드의 오차를 평균화하여 각 pi에 해당하는 전체 유효성 검사 오류율을 계산한다. (데이터를 k개의 조각으로 나눔)
     - 가장 낮은 유효성 검사 오류율을 제공하는 하이퍼파라미터 p*를 선택
     - p*를 사용하여 전체 교육 세트인 D.train의 최종 모델을 학습한다

3. ### Nested Cross-Validation

   - 교차 검증 접근 방식을 확장하여 최종 모델의 **일반화 성능**을 추가로 추정합니다.
     - 교차 검증 접근 방식은 최종 모델만 반환한다.
   - 기본 단계
     - D를 k개의 동일한 크기의 폴드로 나누기
     - i번째 실행 중에서(i = 1, 2, …k)
       - K폴드 중 하나를 D.test(i)로 선택합니다.
       - D.train(i)에 교차 검증 접근 방식을 적용하여 모델 교육 및 선택
       - 선택한 모델을 D.test(i)에 적용하여 테스트 오류 Ei를 얻는다.
     - 평균 검정 오류율 E 계산

#### 요약

1. 데이터를 train과 test로 나눔 (D)
2. D.train도 validation과 train으로 나눔(D.tr D.val)
3. train용(D.tr) 데이터 모델을 만들고 validation에서 최적의 파라미터를 선택함
4. 그렇게 선택된 파라미터에 대해서 최종성능을 D.test로 측정함
5. 이 과정을 여러번 수행
