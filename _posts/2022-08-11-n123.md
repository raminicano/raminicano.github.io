---
layout: single
title: "귀무가설, 1종오류, 단(양)측검정"
categories: review
tag: [코드스테이츠, python, 통계]
toc: true
---



# 개념정리



## 가설검정

- 관심 있는 특정 모집단의 특성에 대한 가설을 세우고 이 가설을 샘플 데이터를 사용하여 검토하는 추론의 과정
  - 우리에게 모집단의 모수에 관한 정보를 주는 것
  - 샘플 데이터의 통계치에 대한 정보를 주는 것이 아님

- **귀무가설** (Null Hypothesis)
  - 디폴트 가설로 특별한 사유가 없다면 받아들여지는 가설
- **대립가설** (Alternative Hypothesis)
  - 귀무가설이 충분한 증거로 기각되었을 때 채택되는 가설
- **검정통계량** (Test Statisitcs)
  - 샘플 데이터에서의 통계량
- **귀무분포** (Null Distribution)
  - 귀무가설을 가정했을 때의 확률분포
- **유의확률** (p-value)
  - 귀무가설을 지지하는 정도
- **표본분포** (Sampling Distribution)
  - 모집단에서 샘플을 복원추출하고 매 추출마다 통계치를 계산하였을 때 그 표본의 통계치로 그린 분포
    - 통계치는 대표적으로 평균을 많이 사용해 평균을 사용한 표본 분포를 대표적으로 기술함





### 귀무가설, 대립가설

- **가설검증**
  - 우리가 알고자 하는 질문을 2개의 대립되는 가설로 세우고 이것의 참과 거짓을 수집한 데이터를 통해 판단
- **귀무가설**
  - 데이터를 수집하기 전 사실이라고 믿는 가설
  - 수학적으로 = 포함
- **대립가설**
  - 귀무가설과 대립되는 가설로 우리가 사실이라고 증명하고자 하는 가설
  - 수학적으로 = 포함x





### 1종오류와 2종오류

- **1종 오류**
  - 귀무가설이 참인데 기각한 경우
    - 어떤차이가 우연히 발생하고 이를 사실이라고 잘못 판단한 경우 (경솔하다)
  - alpha = 유의수준
    - 귀무가설이 참인데도 불구하고 기각할 확률
    - 0.05보다 작으면 귀무 가설을 잘못 기각할 가능성이 5% 미만
  - 1종 오류가 치명적인 경우
    - 사람의 유죄를 판결하는 재판
  - 일반적으로 1종 오류 최소화하게 가설을 설계함
- **2종 오류**
  - 귀무가설이 거짓인데 기각하지 않은 경우
    - 어떤 차이가 발생한 것이 사실이지만 우연히 일어났다고 잘못 판단한 경우 (신중하다)
  - beta

![type12error](https://user-images.githubusercontent.com/97875918/184159629-3d565da0-75e7-42a0-b68f-228402dd9f41.JPG)


- 위 그림과 같이 1종오류와 2종류는 동시에 줄일 수 없음





## 검정 방법론

### 단측검정

  

![image](https://user-images.githubusercontent.com/97875918/184161247-c84f3388-a7a3-4a12-b7ba-f592ec99644c.png)

### 양측검정



![image](https://user-images.githubusercontent.com/97875918/184161371-0c89aece-cee9-4b11-bf59-3e79331cbca2.png)

### 가설채택 방법

1. **신뢰구간 확인**

   - 샘플 데이터로 평균의 표본 분포를 시뮬레이트

     - ```python
       means = []
       for _ in range(10000):
         bootsample= drug[drug['성장호르몬_투약'] == True].sample(150, replace=True)
         means.append(bootsample.키.mean())
       ```

   - 이 분포에서 95% 신뢰구간을 확인함

     - ```python
       low, upper = np.percentile(means, 2.5),np.percentile(means, 97.5) 
       plt.hist(means, alpha=0.5)
       plt.axvline(x=low, color='r')
       plt.axvline(x=upper, color='r', label='95% Confidence \n Interval')
       plt.axvline(x=172.5, color='g', label = 'Upper Limit for \n Null Hypothesis')
       plt.legend(fontsize=10);
       ```

   - 귀무가설이 표본 분포에서 어디에 해당하는지 확인하여 귀무가설 기각 유무 결정

2. **p-value 확인**

   - p-value

     - 귀무가설이 맞다는 전제 하에 관측된 사건에서 귀무가설에 반하는 사건이 일어날 확률을 의미
     
   - 샘플 데이터로 평균의 표본 분포를 시뮬레이트 한 뒤 표준 편차를 변수에 저장
   
   - 귀무가설과 대립가설의 가장근접한 값과 위의 표준편차를 이용해 귀무 분포를 시뮬레이트
   
  - 정규분포 모양(중심극한정리)
   
    - ```python
         # 귀무 u <= 172.5 / 대립 u > 172.5 일때
      null_vals = np.random.normal(172.5, sample_std, 10000) 
         # 귀무 u섭취 <= u미섭취 / 대립 u섭취 > u미섭취
      null_vals = np.random.normal(0, sample_diff_std, 1000) # 우변으로 넘기면 0됨
      ```
   
   - 위의 기무 분포에 샘플 데이터의 평균값이 어디 있는지 확인
   
   - 샘플 데이터보다 큰 면적을 확인
   
  - 0.05보다 작으면 채택


#### p-value의 한계

- p-value는 효과의 크기(effect size)와 표본의 크기(n)의 정보를 한꺼번에 담고 있음
  - 효과의 크기가 커지거나 (ex. 표본 평균간의 차이)
  - 표본의 크기가 커지면
  - p-value가 한없이 작아짐
    - 이러한 문제로 인해 빅데이터 분석에서는 통계적 유의성을 따지기 위해 제 역할을 못함





## 카이제곱 검정

### 교차분석

- 두 범주 변인 간 관게가 상호 독립인지 상호 연광성을 맺고 있는지 검증하는 방법

- 적합도 검정, 독립성 검정, 동일성 검정에 사용됨

- 카이제곱 검정 통계량을 이용

- 카이제곱 교차분석

  - 실제로 나온 관찰빈도와 각 셀에서 통계적으로 기대할 수 있는 빈도(기대 빈도) 간에 얼마만큼 차이가 있는지를 카이제곱 분포를 참조해 통계적으로 검증하는 통계기법
  - 기대빈도
    - 모집단의 빈도 모수와 일치하는 값

  



### 적합도 검정

- one sample 카이제곱 test
- k개의 범주를 가지는 한개의 요인에 대해서 어떤 이론적 분포를 따르고 있는지 검정하는 방법
- 관측값들이 어떤 이론적 분포를 따르고 있는지 알아볼 수 있음
- 모집단 분포에 대한 가정이 옳게 됐는지를 관측자료와 비교하여 검정
- 귀무가설 : 실제분포(관칠빈도)와 이론적 분포(기대빈도) 간에는 차이가 없다. (두 분포가 일치한다.)
- 대립가설 : 실제분포(관칠빈도)와 이론적 분포(기대빈도) 간에는 차이가 있다. (두 분포가 일치하지 않는다.)



### 독립성 검정

- two sample 카이제곱 test
- 모집단이 두 개의 변수 A,B에 의해 범주화됐을 대 이 두변수들 사이의 관계가 독립인지 아닌지를 검정하는 것을 의미
- 모집단을 범주화하는 기준이 되는 두 변수 A,B가 서로 독립적으로 관측값에 영향을 미치는지의 여부를 검정하는 것
- 귀무가설 : 두 변수 사이에는 연관이 없다. (독립이다)
- 대립가설 : 두 변수 사이에는 연관이 있다. (종속이다)











[출처1](https://jae-eun-ai.tistory.com/51)

----





# 관련 함수

## 카이제곱 검정

### crosstab

```python
pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)
```

- 2개 이상의 factor에 대한 간단한 교차표를 계산한다.
- 값 배열과 집계 함수를 전달하지 않는 한 디폴트로 factor의 빈도표를 계산한다.
- index : array-like, Series, or list of arrays/Series
  - 행에서 그룹화할 값
- columns : array-like, Series, or list of arrays/Series
  - 열에서 그룹화할 값
- values : array-like, optional
  - factor에 따라 집계할 값의 배열
  - aggfunc를 지정해야 함
- rownames : sequence, default None
  - 통과되면 전달된 행 배열의수와 일치해야 함
- colnames : sequence, default None
  - 전달된 경우 전달된 열 배열의수와 일치해야 함
- aggfunc : function, optional
  - 지정한 경우 values도 지정해야 한다
- margins : bool, default False
  - 행/열 에 여백을 추가한다.
  - 행과 열의 가장자리에 합을 기입해서 보여줄 수 있는 변수이다.
- margins_name : str, default ‘All’
  - margins가 True일 때 합계를 포함할 행/열의 이름
- dropna : bool, default True
  - 항목이 모두 nan인 열은 포함하지 않음
- normalize : bool, {‘all’, ‘index’, ‘columns’}, or {0,1}, default False
  - 모든 값을 값의 합으로 나누어 정규화한다.
  - 'all' or True : 모든 값에 대해 정규화 
  - 'index' : 각 행에서 정규화
  - 'columns' : 각 열에서 정규화
  - margins 가 'True' : margin값에 대해서도 정규화

### chisquare

```python
scipy.stats.chisquare(f_obs, f_exp=None, ddof=0, axis=0)
```

- 범주형 데이터에 지정된 빈도가 있다는 귀무가설을 검정한다.
- f_obs : array_like
  - 각 범주에서 관측된 빈도수
- f_exp : array_like , optional
  - 각 범주의 예상빈도
  - 디폴트 : 범주는 동일한 확률로 간주
- ddof : int, optional
  - 자유도의 델타 : p-value에 대한 자유도 조정
  - p-value는 자유도가 k-1-ddof인 카이제곱 분포를 사용하여 계산됨
    - 여기서 k는 관측된 빈도수의 수이다.
  - 디폴트 : 0
- axis : int or None, optional
  - 테스트를 적용할 브로드캐스트 결과 축 f_obs 및 f_exp. 
  - 축이 없으면 f_obs의 모든 값이 단일 데이터 집합으로 처리됨
  - 디폴트 :  0
