---
layout: single
title: "CH4 Classification : Alternative Techniques"
categories: coding
---



## Ensemble Methods

- **다중** 분류기의 예측을 **집계**하여 분류 정확도를 향상시키는 기술
- 기본 아이디어
  - 교육 데이터에서 **기본 분류기** 집합 구성
  - 각 기본 분류자가 작성한 예측에 **투표하여** 분류 수행



#### Rationale for Ensemble Method

- 예시
  - 25개의 이진 분류기로 구성된 앙상블을 고려한다.
    - 각 오류율은 e = 35% 라고 가정
  - **다수결**로 테스트 사례를 분류한다고 가정
    - 기본 분류자가 예측한 내용에 대해
  - 기본 분류자가 동일한 경우
    - 모든 기본 분류기가 동일한 실수를 한다. → e는 35%를 유지
    - 똑같이 yes 또는 no를 대답할 것이기에 앙상블 의미 없음
  - 기본 분류기가 독립적인 경우(즉, 오류는 상관 없음)
    - 기본 분류기의 절반 이상이 잘못 예측하는 경우에만 앙상블이 잘못된 예측을 한다.
    - 이 경우 앙상블 분류기의 오류율은 다음과 같음
- 좋은 앙상블 분류기에 필요한 두 가지 조건
  - 기본 분류기는 서로 **독립적**이어야 한다.
  - 기본 분류기는 무작위 추측**(e < 0.5)보다 더 잘** 수행되어야 한다.

#### Methods for Constructing an Ensemble

1. 교육 세트를 조작하여
   - 원본 데이터를 **재샘플링**하여 **여러 개**의 교육 세트
   - 각 교육 세트에서 분류기 구성
   - 예: **bagging, boosting**
2. 입력 피쳐를 조작하여
   - 각 교육 세트를 구성할 입력 피쳐의 **하위 집합** 선택
     - 부분 집합은 무작위로 선택하거나 도메인 전문가에 의해 선택될 수 있다.
   - 각 교육 세트에서 분류기 구성
   - 예) **random forest**
3. 학습 알고리즘을 조작하여
   - 동일한 교육 데이터에 여러 번 알고리즘 적용 (동일한 모델이지만 하이퍼파라미터를 다르게 주어 서로다른 모델이 되는 경우)
   - 이렇게 하면 서로 다른 분류기가 생성
   - 예
     - ANN(네트워크 토폴로지 또는 초기 가중치가 다른 경우)
     - 의사 결정 트리(분할 전략이 다른 경우)
       - (ex) 분할할 상위 k 속성 중 하나를 임의로 선택합니다.

#### Voting Approahces in Ensemble Methods

- x를 검정 예시로 보자.
-  C1(x), C2(x), …, Ck(x)를 k개의 기본 분류기에 의한 예측이라고 하자.
- 접근방법 1: **단순 다수결**
  - C1(x), C2(x), …, Ck(x)의 과반수 투표를 실시
- 접근방법 2 : **가중 다수결**
  - w1C1(x), w2C2(x), …, wkCk(x)의 과반수 투표를 실시
  - Ci(x)의 무게 wi는 정확도 또는 중요성을 나타낸다.

#### Bias and Variance

- Bias (모델의 편향성)
  - 모형의 평균 예측이 평균 목표값에 얼마나 가까운지
  - 의사 결정 경계가 단순한 모형은 일반적으로 **높은** 편향을 보인다.
- Variance (모델의 편차)
  - 훈련 세트의 작은 변화에 대한 모델의 예측의 **안정성**
  - 복잡한 결정 경계를 가진 모형은 일반적으로 **높은** 분산을 나타낸다.
  - 오버피팅의 위험성
  - ex. ANN

#### Bias-Variance Trade-Off and Ensemble

- Bias-Variance Trade-Off 
  - 복잡한 모형 → bias은 낮지만 variance은 높음 → **오버피팅**
  - 단순한 모형 →  variance은 낮지만 bias은 높음 → **언더피팅**
-  앙상블 방법은 **bias는 낮지만 variance은 높은** 기본 분류기와 함께 사용했을 때 가장 개선된 것으로 나타났다.
  - 각 기본 분류기는 훈련 세트의 작은 변화조차도 다른 예측을 초래할 수 있기 때문에 과적합에 취약하다.
- 여러 기본 분류기의 반응을 조합하여 앙상블 방식으로 **전체 분산을 줄일 수 있다.**
  - 따라서 앙상블 방법은 주로 예측의 **분산을 낮춤**으로써 더 나은 성능을 보여준다.

#### Bagging

- **b**ootstrap **agg**regat**ing** 라고도 함
- 기본 절차
  - 데이터 세트에서 반복 샘플링(**교체 포함**)
    - **균일한** 확률 분포에 따라
    - 각 부트스트랩 샘플의 크기는 원래 데이터와 **동일**
  - 각 부트스트랩 샘플에 대한 기본 분류자 교육
  - 가장 많은 표를 받은 클래스에 테스트 인스턴스 할당
  - +) 정리
    1. 뽑힐 때는 완전히 동일하게(원래 데이터의 갯수만큼 뽑음)
    2. 완전 랜덤하게 뽑기
    3. 뽑은 다음 다시 돌려놓기

##### Sample in Bagging

- 각 인스턴스는 **동일한** 확률로 선택
- 각 부트스트랩 샘플의 크기는 원래 데이터와 **동일**
- **복원추출**로 샘플링 완료
  - 일부 인스턴스는 동일한 교육 세트에 여러 번 나타날 수 있다.
  - 기타는 교육 세트에서 생략할 수 있다.
- 평균적으로 샘플에는 원래 데이터 세트의 약 **63%**가 포함됩니다.
  - 각 표본에는 1 – (1 – 1/N)^n의 확률이 있기 때문
    - N: 원래 데이터 세트의 인스턴스 수
  - N이 충분히 크면 이 확률은 1 – 1/e = 0.632로 수렴된다.

##### Example : Bagging



##### Notes on Bagging

- 앙상블 방법을 사용하는 또 다른 장점
  - 대상 함수의 표현을 강화
  - 단순한 분류자를 결합하면 복잡한 의사 결정 경계로 이어질 수 있다.
- 배깅은 기본 분류자의 **분산**을 줄여 일반화 오류를 개선
  - 기본 분류기의 분산이 높은 경우, 배깅은 훈련 데이터의 랜덤 변동과 관련된 오류를 줄이는 데 도움이 된다.
  - 기본 분류기의 편향이 높은 경우, 배깅은 기본 분류기의 성능을 크게 향상시키지 **못할 수** 있다(예: 더 작은 훈련 세트)