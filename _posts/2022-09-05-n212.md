---
layout: single
title: "Cross-Validation, 과적합, 편향/분산"
categories: review
tag: [python, ML]
toc: true
---

# Data Split & Validation

## Hold-Out

- 2 way holdout
  1. training set : 모델을 학습시키기 위한 세트
  2. test set : 모델을 테스트하기 위한 세트
     - 의미있는 test set
       - 데이터 사이즈가 충분히 큼
       - 테스트 데이터가 전체 데이터를 대표할 수 있음
         - 훈련세트와 다른 특징을 가진 데이터이면 안됨
- 주의할 점
  - 테스트 세트를 여러번 사용해서는 안됨
  - 그럼 모델을 평가하고 개선시킬 때는?
- 3 way holdout
  1. train set
     - 모델 학습을 위한 세트
     - 학습
  2. validation set
     - 모델 검증을 위한 세트
     - 모의고사
  3. test set
     - 모델 테스트를 위한 세트
     - 수능
  4. 오직 모델 평가만을 위한 세트 추가
     - 데이터의 크기가 충분히 클 때
     - 과정
       - 훈련세트로 모델을 만들고
       - 검증 세트로 모델을 여러번 평가, 개선 후
       - 가장 마지막에 단 한번 테스트 세트를 이용해 결과를 확인







## Cross-Validation

1. 3 way hold out의 문제점
   - 데이터 크기가 작을 경우 적절하지 않음
     - 모델 학습에 사용할 수 있는 데이터의 양이 줄어들어 모델이 데이터의 패턴을 정확히 파악할 수 x
     - 검증 세트의 크기가 충분히 크지 않다면 예측 성능에 대한 추정이 부정확할 것
   - 모델 선택의 문제
     - 모델 선택
       - 문제를 해결하기 위해 어떤 알고리즘을 사용할 것인지
       - 어떤 하이퍼 파라미터를 사용할 것인지
     - hold out 검증은 학습 결과가 무작위로 선택된 학습 및 검증 세트에 의해 달라질 수 있다.
       - 모델의 신뢰성에 의문
2. cross-validation(cv, 교차검증)
   - 3ho 과 달리 훈련 세트의 모든 샘플이 검증에 사용됨
   - k-fold cross-validation
     - 일반적으로 가장 흔히 사용
     - 방법
       - <img src="https://user-images.githubusercontent.com/97875918/188466718-171110d3-4c99-4e2e-9d9e-c991f65eabdf.png" alt="image" style="zoom:80%;" />
       - 데이터를 k개로 분할
       - 1개의 파트는 검증세트로 이용되고 나머지 k-1개 파트는 모두 훈련에 사용
       - k번의 검증 결과를 종합해 전체 모델의 성능을 평가
     - `from sklearn.model_selection import KFold`
       - 데이터를 k개로 분할 가능
     - `from sklearn.model_selection import cross_val_score` 
       - 각 fold의 스코어 확인 가능
     - 장점
       - 데이터를 무작위로 나눔
         - 이런 경우 훈련 세트에 분류하기 어려운 데이터가 담기고 테스트 세트에는 분류하기 쉬운 데이터가 들어가 테스트 세트의 정확도가 높게 나옴
       - 검증세트에 각 샘플이 정확하게 한 번씩 들어감
       - 데이터를 효과적으로 사용할 수 있음
         - 보통 75%를 학습에 사용
         - 5-fold의 경우 매 반복에서 데이터의 80%(4/5)를 학습에 사용
         - 10-fold의 경우 매 반복에서 데이터의 90%(9/10)를 학습에 사용
     - 단점
       - 연산비용이 증가함
   - LOOCV (leave-one-out cv)
     - 폴드 하나에 샘플이 하나만 들어있는 k-fold 검증
     - 단 하나의 관측값(x1, y1)만을 validation set으로 사용하고, 나머지 n-1개 관측값은 train set으로 사용
       - ![image](https://user-images.githubusercontent.com/97875918/188475623-de838ac6-99f4-479e-a0ae-a8752172c414.png)
     - 데이터 셋이 클 때에는 시간 오래걸리지만 작은 데이터셋에서는 좋은 결과
       - 폴드 하나에 데이터가 하나만 있기에 
   - 시계열 교차검증 방법
     - 시계열 데이터의 경우 전후 데이터 사이의 상관관계가 존재하기 때문에 다른 방법 사용
     - time series cross-validation
       - `from sklearn.model_selection import TimeSeriesSplit`
       - n_split의 갯수만큼 훈련용 + 검증용 데이터 셋을 만든다.
       - 훈련용 데이터는 검증용보다 항상 앞선 시간으로 할당된다.
       - <img src="https://user-images.githubusercontent.com/97875918/188470666-323c5371-8b9d-41f2-a526-563733ae0ba5.png" alt="image" style="zoom:60%;" />
     - blocked cross-validation
       - 훈련용과 검증용 데이터의 크기를 모든 교차 검증 횟수에서 고정시킴
       - 지원하는 라이브러리가 없어 직접 구현해야 함
       - <img src="https://user-images.githubusercontent.com/97875918/188471044-de4ef207-7f8a-43b3-8bcc-3ad0c462eaff.png" alt="image" style="zoom:60%;" />
   - 이 경우에도 test 셋은 분리해두어야 함
3. 적절한 사용 방법
   - ![image](https://user-images.githubusercontent.com/97875918/188467452-39b24ae4-d9db-45cc-b08d-f22e4348881c.png)
   - 보통 회귀에서는 k-fold, 분류에서는 계층별 k-fold의 기본값이 잘 작동됨





# 과적합(overfitting) & 과소적합(underfitting)





## 과(대)적합

- 훈련 데이터셋의 디테일과 노이즈까지 모두 학습해 새로운 데이터를 잘 예측하지 못하는 현상
- 과적합된 모델은 훈련 데이터셋에서의 성능은 높지만 테스트 데이터셋에서의 성능은 매우 낮음
- 유연성이 높은 모델이나 비선형 모델에서 나타날 가능성이 높음
  - tree-based model이 대표적



## 과소적합

- 과소적합은 훈련 데이터셋도 제대로 학습하지 못해 새로운 데이터를 잘 예측하지 못하는 현상
- 훈련 데이터셋에서의 성능과 테스트 데이터셋에서의 성능 모두 낮음







# 편향(Bias)과 분산(Variance)



## 편향

- 모델의 예측값과 실제값과의 차이
- 잘못된 알고리즘 가정에서 오는 에러
- ex) 단순선형회귀모델은 편향이 크고 다항회귀모델은 편향이 작다.
- 편향이 큰 모델은 특성과 타겟 간의 관계를 제대로 파악하지 못하기 때문에 과소적합이 일어날 수 있음



## 분산

- 서로 다른 데이터가 들어왔을 경우 모델의 예측값이 변동되는 양을 의미
- 분산 에러는 훈련 데이터세트의 결과에서 작은 변동이 있으 ㄹ경우 모델이 얼마나 민감하게 반응하는지에 따른 에러
- ex) 단순선형회귀는 분산이 작고 다항선형회귀는 분산이 크다
- 분산이 큰 모델은 훈련 데이터의 노이즈까지 학습해 과적합이 일어날 수 있음



## 분산과 편향의 Trade-off

- MSE 식을 reducible, irreducible 에러로 나누어 표현
  - Bias 에러 + Variance 에러 + irreducible 에러
  - MSE가 고정되어 있다는 가정
    - 분산에러가 커지면 편향 에러는 작아지고 편향에러가 커지면 분산에러는 작아짐
- 모델의 복잡도를 변경해 일반화가 잘 되는 지점을 찾아야 함
  - 모델이 복잡해질수록 분산 에러가 커지고 모델이 단순해질수록 편향에러가 커짐
  - 모델의 복잡도는 데이터의 크기에 따라 달라질 수 있음







